#separator:Tab
#html:true
#notetype:Basic
#deck:Egzamin Magisterski - Ręcznie
#tags column:3

Porównać 'siłę wyrazu' automatu skończonego, automatu ze stosem oraz maszyny Turinga. Jakie klasy języków rozpoznaje każdy z nich?	<b>Automat Skończony (FA)</b> → <b>Języki regularne (Typ 3)</b><br>• Brak pamięci - tylko aktualny stan<br>• Równoważny wyrażeniom regularnym<br>• Przykład: identyfikatory, wzorce tekstu<br>• NIE rozpozna: aⁿbⁿ (wymaga liczenia)<br><br><b>Automat ze Stosem (PDA)</b> → <b>Języki bezkontekstowe (Typ 2)</b><br>• Pamięć: stos LIFO (nieskończony, ale ograniczony dostęp)<br>• Potrafi liczyć pary: aⁿbⁿ ✓<br>• NIE rozpozna: aⁿbⁿcⁿ (wymaga 3 liczników)<br>• UWAGA: DPDA ⊂ NPDA (niedeterministyczny silniejszy!)<br><br><b>Maszyna Turinga (TM)</b> → <b>Języki rekurencyjnie przeliczalne (Typ 0)</b><br>• Pamięć: nieskończona taśma R/W<br>• Rozpoznaje wszystko co obliczalne (teza Churcha-Turinga)<br>• DTM ≡ NTM pod względem mocy	pyt01 AISDI automaty hierarchia_chomskiego

Dlaczego automat skończony nie może rozpoznać języka L = {aⁿbⁿ}?	Automat skończony <b>nie ma pamięci</b> poza swoim stanem. Aby rozpoznać aⁿbⁿ, musiałby "zapamiętać" ile było liter 'a', żeby porównać z liczbą 'b'.<br><br>Skończona liczba stanów = skończona "pamięć" = nie może liczyć do dowolnie dużego n.<br><br><b>Dowód formalny:</b> Lemat o pompowaniu - dla słowa aᵖbᵖ (gdzie p = stała pompowania), pompując część y w xyz, dostaniemy nierówną liczbę a i b.	pyt01 AISDI automaty pumping_lemma

Dlaczego DPDA jest słabszy niż NPDA, ale DFA = NFA?	<b>DFA = NFA</b> (równoważne):<br>Każdy NFA można przekształcić w DFA przez konstrukcję podzbiorową (powerset construction). Stany DFA = podzbiory stanów NFA.<br><br><b>DPDA ⊂ NPDA</b> (DPDA słabszy):<br>Stos wymaga "odgadnięcia" kiedy skończyć odkładanie i zacząć zdejmowanie. Przykład: palindromy parzyste L = {wwᴿ} - NPDA "zgaduje" środek słowa, DPDA nie może.<br><br>Kluczowa różnica: przy stosie niedeterminizm daje realną przewagę, przy samych stanach - nie.	pyt01 AISDI automaty dpda_npda

Omówić i porównać algorytmy najkrótszej ścieżki: Dijkstry, Bellmana-Forda, A*.	<b>Dijkstra</b> (1959) - zachłanny, SSSP<br>• Wymóg: wagi ≥ 0<br>• Złożoność: O(V²) lub O((V+E)log V) z kopcem<br>• Idea: wybieraj wierzchołek o najmniejszej znanej odległości<br><br><b>Bellman-Ford</b> (1958) - programowanie dynamiczne<br>• Działa dla ujemnych wag (wykrywa ujemne cykle)<br>• Złożoność: O(V·E)<br>• Idea: V-1 iteracji relaksacji wszystkich krawędzi<br><br><b>A*</b> (1968) - heurystyczny, single-pair<br>• Wymóg: heurystyka dopuszczalna h(n) ≤ h*(n)<br>• f(n) = g(n) + h(n) (koszt dotarcia + szacowany koszt do celu)<br>• Znacznie szybszy od Dijkstry dla konkretnego celu	pyt02 AISDI algorytmy_grafowe najkrotsza_sciezka

Dlaczego algorytm Dijkstry nie działa dla ujemnych wag?	Dijkstra oznacza wierzchołki jako "zakończone" gdy je przetworzy - zakłada, że znaleziona odległość jest ostateczna.<br><br><b>Problem:</b> Ujemna krawędź może później "poprawić" już zakończony wierzchołek.<br><br><b>Przykład:</b><br>S→C = 2 (Dijkstra ustala jako finalne)<br>S→A→B→C = 1 + (-5) + 1 = -3 < 2<br><br>Bellman-Ford rozwiązuje to robiąc V-1 iteracji po WSZYSTKICH krawędziach.	pyt02 AISDI dijkstra ujemne_wagi

Co to jest heurystyka dopuszczalna w A* i dlaczego jest ważna?	<b>Heurystyka dopuszczalna (admissible):</b> h(n) ≤ h*(n)<br>czyli heurystyka nigdy nie przeszacowuje rzeczywistego kosztu do celu.<br><br><b>Dlaczego ważna:</b><br>• Gwarantuje optymalność - A* znajdzie najkrótszą ścieżkę<br>• Jeśli h(n) > h*(n), A* może pominąć optymalną ścieżkę<br><br><b>Przykłady:</b><br>• Odległość euklidesowa (linia prosta) - zawsze ≤ rzeczywistej trasy<br>• h(n) = 0 → A* = Dijkstra (bezpieczne, ale wolne)<br><br><b>Heurystyka spójna (consistent):</b> h(n) ≤ c(n,n') + h(n') - silniejsza, przyspiesza A*	pyt02 AISDI a_star heurystyka

Czym jest redundancja w bazach danych i jakie anomalie powoduje?	<b>Redundancja</b> = ta sama informacja przechowywana w wielu miejscach.<br><br><b>Trzy anomalie:</b><br><br>1. <b>Anomalia wstawiania</b><br>Nie można dodać danych bez innych danych.<br>Przykład: nowy kurs bez studentów<br><br>2. <b>Anomalia usuwania</b><br>Usunięcie danych powoduje utratę innych informacji.<br>Przykład: usunięcie ostatniego studenta kursu = utrata info o kursie<br><br>3. <b>Anomalia modyfikacji</b><br>Zmiana wymaga aktualizacji wielu wierszy.<br>Przykład: zmiana nazwiska prowadzącego = update wielu rekordów<br><br><b>Rozwiązanie:</b> Normalizacja - dekompozycja tabel	pyt03 BD2 redundancja anomalie

Wyjaśnij postacie normalne 1NF, 2NF, 3NF.	<b>1NF - Pierwsza Postać Normalna</b><br>• Atomowość wartości (brak list/tablic w komórkach)<br>• Istnieje klucz główny<br><br><b>2NF - Druga Postać Normalna</b><br>• Spełnia 1NF<br>• Brak częściowych zależności (atrybut zależy od CAŁEGO klucza złożonego, nie od części)<br>• Dotyczy tylko tabel z kluczem wielokolumnowym<br><br><b>3NF - Trzecia Postać Normalna</b><br>• Spełnia 2NF<br>• Brak przechodnich zależności (A→B→C, gdzie B nie jest kluczem)<br>• Atrybuty wtórne zależą TYLKO od klucza<br><br><b>Hierarchia:</b> 5NF ⊂ 4NF ⊂ BCNF ⊂ 3NF ⊂ 2NF ⊂ 1NF	pyt03 BD2 normalizacja postacie_normalne

Co to jest BCNF i czym różni się od 3NF?	<b>BCNF (Boyce-Codd Normal Form):</b><br>Dla każdej nietrywialnej zależności funkcyjnej X→Y, X musi być nadkluczem.<br><br><b>Różnica od 3NF:</b><br>3NF dopuszcza: X→A gdzie A jest atrybutem pierwszym (należy do klucza)<br>BCNF: NIE dopuszcza - zawsze X musi być nadkluczem<br><br><b>Przykład naruszenia 3NF ale spełnienia BCNF:</b><br>Relacja z kluczami kandydującymi {A,B} i {A,C}<br>Zależność B→C narusza BCNF (B nie jest nadkluczem)<br>ale spełnia 3NF (C jest atrybutem pierwszym)<br><br><b>Praktyka:</b> 3NF zwykle wystarcza, BCNF może utrudnić dekompozycję	pyt03 BD2 bcnf normalizacja

Co oznacza ACID w kontekście transakcji bazodanowych?	<b>A - Atomicity (Atomowość)</b><br>Transakcja wykonuje się w całości lub wcale. Brak częściowych zmian.<br><br><b>C - Consistency (Spójność)</b><br>Dane przechodzą z jednego spójnego stanu w drugi. Reguły biznesowe zawsze spełnione.<br><br><b>I - Isolation (Izolacja)</b><br>Równoległe transakcje nie widzą swoich pośrednich zmian. Brak efektów ubocznych.<br><br><b>D - Durability (Trwałość)</b><br>Zatwierdzone zmiany przetrwają awarie systemu.<br><br><b>Przykład - przelew bankowy:</b><br>Bez A: awaria po odjęciu = utrata pieniędzy<br>Bez C: saldo ujemne mimo ograniczenia<br>Bez I: inna transakcja widzi stan pośredni<br>Bez D: po COMMIT dane giną	pyt04 BD2 acid transakcje

Dlaczego baza danych stanowi dobry fundament systemów informatycznych?	<b>1. Transakcyjność (ACID)</b><br>Gwarancja spójności i niezawodności operacji<br><br><b>2. Niezależność danych</b><br>• Fizyczna: zmiana indeksów/partycjonowania bez zmiany aplikacji<br>• Logiczna: zmiana schematu z minimalnym wpływem (widoki)<br><br><b>3. Współbieżność</b><br>Wiele aplikacji jednocześnie: blokady, MVCC, poziomy izolacji<br><br><b>4. Integralność</b><br>• Ograniczenia: PK, FK, CHECK, NOT NULL<br>• Wyzwalacze i procedury składowane<br><br><b>5. Optymalizacja</b><br>Automatyczny optymalizator zapytań, indeksy, statystyki<br><br><b>6. Bezpieczeństwo</b><br>Kontrola dostępu, audyt, szyfrowanie	pyt04 BD2 bazy_danych fundament

Jakie są główne kategorie elementów STL i jak są powiązane?	<b>4 główne kategorie:</b><br><br>1. <b>KONTENERY</b> - struktury przechowujące dane<br>• Sekwencyjne: vector, list, deque<br>• Asocjacyjne: map, set (drzewo czerwono-czarne)<br>• Nieuporządkowane: unordered_map (hash table)<br><br>2. <b>ITERATORY</b> - abstrakcja wskaźnika<br>• input, output, forward, bidirectional, random access<br>• Łączą kontenery z algorytmami<br><br>3. <b>ALGORYTMY</b> - operacje na danych<br>• sort, find, transform, copy, accumulate<br>• Działają na iteratorach, nie na kontenerach bezpośrednio<br><br>4. <b>FUNKTORY</b> - obiekty wywoływalne<br>• less<T>, greater<T>, plus<T><br>• Lambdy od C++11<br><br><b>Powiązanie:</b> Algorytmy operują na kontenerach PRZEZ iteratory, parametryzowane funktorami	pyt05 PROI stl cpp

Kiedy użyć vector, a kiedy list w STL?	<b>std::vector</b> - tablica dynamiczna<br>• Dostęp O(1) przez indeks<br>• Wstawianie na końcu O(1) amortyzowane<br>• Wstawianie w środku O(n) - przesunięcie elementów<br>• Cache-friendly (ciągła pamięć)<br>→ <b>Użyj gdy:</b> częsty dostęp losowy, głównie dodajesz na koniec<br><br><b>std::list</b> - lista dwukierunkowa<br>• Dostęp O(n) - brak indeksowania<br>• Wstawianie/usuwanie O(1) w dowolnym miejscu (po znalezieniu)<br>• Nie invaliduje iteratorów przy modyfikacji<br>→ <b>Użyj gdy:</b> częste wstawianie/usuwanie w środku, iteratory muszą pozostać ważne<br><br><b>Praktyka:</b> vector w 95% przypadków (cache matters!)	pyt05 PROI stl vector_list

Różnica między map a unordered_map w STL?	<b>std::map</b> (drzewo czerwono-czarne)<br>• Operacje: O(log n)<br>• Elementy posortowane według klucza<br>• Wymaga operator< dla klucza<br>• Stabilna wydajność<br><br><b>std::unordered_map</b> (tablica haszująca)<br>• Operacje: O(1) średnio, O(n) pesymistycznie<br>• Elementy nieposortowane<br>• Wymaga std::hash dla klucza<br>• Szybsza dla dużych zbiorów z dobrą funkcją hash<br><br><b>Kiedy map:</b><br>• Potrzebujesz posortowanych kluczy<br>• Iterujesz po zakresach<br><br><b>Kiedy unordered_map:</b><br>• Tylko lookup/insert (brak iteracji po kolejności)<br>• Duże zbiory danych	pyt05 PROI stl map_unordered

Jaki jest cel three-way handshake w TCP?	<b>Cele:</b><br>1. <b>Nawiązanie połączenia</b> - obie strony zgadzają się komunikować<br>2. <b>Synchronizacja ISN</b> - wymiana początkowych numerów sekwencyjnych<br>3. <b>Uzgodnienie parametrów</b> - MSS, Window Scale, SACK<br><br><b>Przebieg:</b><br>1. <b>Klient → SYN</b>, seq=x (stan: SYN_SENT)<br>2. <b>Serwer → SYN+ACK</b>, seq=y, ack=x+1 (stan: SYN_RECEIVED)<br>3. <b>Klient → ACK</b>, seq=x+1, ack=y+1 (stan: ESTABLISHED)<br><br><b>Dlaczego 3 kroki?</b><br>• 2 kroki: serwer nie wie czy klient otrzymał jego ISN<br>• 3 kroki: obie strony potwierdziły swoje ISN	pyt08 SKM tcp handshake

Co to jest numer sekwencyjny w TCP i jaka jest jego wartość początkowa?	<b>Sequence Number (SEQ)</b> = numer pierwszego bajtu danych w segmencie.<br><br><b>Interpretacja:</b><br>• SEQ=1000, 500 bajtów danych → następny segment ma SEQ=1500<br>• Umożliwia składanie segmentów w kolejności<br>• Wykrywanie duplikatów i braków<br><br><b>Acknowledgment Number (ACK)</b> = numer NASTĘPNEGO oczekiwanego bajtu.<br>ACK=1500 oznacza: "otrzymałem wszystko do bajtu 1499"<br><br><b>Wartość początkowa (ISN):</b><br>• Losowa (nie 0!) ze względów bezpieczeństwa<br>• Zapobiega atakom typu session hijacking<br>• Historycznie: ISN = (timer * 250) mod 2³²<br>• Współcześnie: kryptograficznie losowy	pyt08 SKM tcp seq_ack

Czym różni się proces od wątku?	<b>PROCES</b><br>• Oddzielna przestrzeń adresowa (izolacja)<br>• Własny PCB (Process Control Block)<br>• Komunikacja: IPC (pipe, socket, shared memory)<br>• Przełączanie: kosztowne (zmiana kontekstu MMU)<br>• Awaria jednego nie wpływa na inne<br><br><b>WĄTEK</b><br>• Współdzieli przestrzeń adresową procesu<br>• Własny: stos, rejestry, PC<br>• Wspólne: kod, dane, heap, pliki<br>• Przełączanie: szybkie (bez zmiany tablic stron)<br>• Awaria jednego = awaria całego procesu<br><br><b>Analogia:</b><br>Proces = mieszkanie (własne zasoby)<br>Wątek = współlokator (wspólna kuchnia, łazienka)	pyt09 SOI procesy_watki

Jakie są problemy synchronizacji wątków i jak je rozwiązać?	<b>PROBLEMY:</b><br><br>1. <b>Wyścig (Race Condition)</b><br>Wynik zależy od kolejności wykonania<br>→ Rozwiązanie: sekcja krytyczna z mutexem<br><br>2. <b>Zakleszczenie (Deadlock)</b><br>Wątki czekają na siebie nawzajem<br>→ Rozwiązanie: kolejność blokad, timeout, wykrywanie<br><br>3. <b>Zagłodzenie (Starvation)</b><br>Wątek nigdy nie dostaje zasobu<br>→ Rozwiązanie: sprawiedliwe szeregowanie, kolejki<br><br>4. <b>Livelock</b><br>Wątki aktywne, ale nie robią postępu<br>→ Rozwiązanie: losowe opóźnienia<br><br><b>MECHANIZMY:</b><br>• Mutex, Semafor, Monitor<br>• Zmienna warunkowa (condition variable)<br>• Read-write lock<br>• Operacje atomowe	pyt09 SOI synchronizacja watki

Warunki konieczne wystąpienia zakleszczenia (deadlock).	<b>4 warunki Coffmana (wszystkie muszą być spełnione):</b><br><br>1. <b>Wzajemne wykluczanie (Mutual Exclusion)</b><br>Zasób może być używany tylko przez jeden proces<br><br>2. <b>Trzymaj i czekaj (Hold and Wait)</b><br>Proces trzyma zasoby czekając na kolejne<br><br>3. <b>Brak wywłaszczania (No Preemption)</b><br>Zasobów nie można odebrać siłą<br><br>4. <b>Cykliczne oczekiwanie (Circular Wait)</b><br>P1→P2→P3→P1 (cykl oczekiwań)<br><br><b>Zapobieganie:</b><br>Złam dowolny warunek:<br>• Ustal globalną kolejność zasobów (łamie 4)<br>• Żądaj wszystkich zasobów naraz (łamie 2)<br>• Pozwól na wywłaszczanie (łamie 3)	pyt09 SOI deadlock warunki

Co to jest stronicowanie i segmentacja? Porównaj.	<b>STRONICOWANIE (Paging)</b><br>• Pamięć dzielona na równe ramki (np. 4KB)<br>• Tablica stron: strona → ramka<br>• Fragmentacja wewnętrzna (ostatnia strona)<br>• Niewidoczne dla programisty<br>• Umożliwia pamięć wirtualną (swap)<br><br><b>SEGMENTACJA (Segmentation)</b><br>• Pamięć dzielona logicznie: kod, dane, stos<br>• Segmenty różnej wielkości<br>• Fragmentacja zewnętrzna<br>• Widoczna dla programisty (ochrona, współdzielenie)<br><br><b>PORÓWNANIE:</b><br>| Cecha | Stronic. | Segment. |<br>| Jednostka | Stała | Zmienna |<br>| Fragmentacja | Wewnętrzna | Zewnętrzna |<br>| Widoczność | Ukryta | Jawna |<br><br><b>Praktyka:</b> Często łączone (segmentacja + stronicowanie)	pyt10 SOI zarzadzanie_pamiecia stronic_segment

Jakie standardy służą do modelowania procesów biznesowych?	<b>BPMN 2.0</b> (Business Process Model and Notation)<br>• Główny standard dla procesów biznesowych<br>• Wykonywalne diagramy (silniki workflow)<br>• Elementy: zdarzenia (kółka), bramki (romby), czynności (prostokąty), przepływy<br>• Swimlanes = odpowiedzialności<br><br><b>UML</b> (Unified Modeling Language)<br>• Diagram aktywności ≈ flowchart<br>• Diagram przypadków użycia<br>• Głównie dla systemów IT, nie procesów biznesowych<br><br><b>EPC</b> (Event-driven Process Chain)<br>• Metodyka ARIS<br>• Zdarzenia → Funkcje → Zdarzenia<br>• Popularne w SAP<br><br><b>Praktyka:</b> BPMN dla biznesu, UML dla IT	pyt11 ISA bpmn modelowanie_procesow

Czym różnią się bramki XOR, AND i OR w BPMN?	<b>XOR (Exclusive Gateway) ◇</b><br>• Dokładnie JEDNA ścieżka wybrana<br>• Rozgałęzienie: warunki wzajemnie wykluczające<br>• Scalenie: czeka na pierwszą (nie synchronizuje)<br>• Przykład: Decyzja tak/nie<br><br><b>AND (Parallel Gateway) ◇+</b><br>• WSZYSTKIE ścieżki aktywowane/wymagane<br>• Rozgałęzienie: równoległe wykonanie<br>• Scalenie: synchronizacja (czeka na wszystkie)<br>• Przykład: Równoległa weryfikacja dokumentów<br><br><b>OR (Inclusive Gateway) ◇○</b><br>• JEDNA LUB WIĘCEJ ścieżek<br>• Rozgałęzienie: aktywuje te, których warunki spełnione<br>• Scalenie: czeka na wszystkie aktywowane<br>• Przykład: Opcjonalne kroki procesu	pyt11 ISA bpmn bramki

Jakie są podstawowe sieciowe modele optymalizacji?	<b>1. Najkrótsza ścieżka (Shortest Path)</b><br>min Σ cᵢⱼxᵢⱼ od s do t<br>Algorytmy: Dijkstra, Bellman-Ford, A*<br><br><b>2. Maksymalny przepływ (Max Flow)</b><br>max przepływ od źródła do ujścia<br>Ograniczenie: przepustowość krawędzi<br>Algorytmy: Ford-Fulkerson, Edmonds-Karp<br><br><b>3. Minimalny koszt przepływu (Min Cost Flow)</b><br>Połączenie: przepływ + koszt jednostkowy<br>Zastosowanie: transport, przydział zadań<br><br><b>4. Problem przydziału (Assignment)</b><br>n pracowników → n zadań, min koszt<br>Każdy pracownik = jedno zadanie<br>Algorytm: Metoda węgierska O(n³)<br><br><b>5. Problem komiwojażera (TSP)</b><br>Najkrótsza trasa przez wszystkie miasta<br>NP-trudny!	pyt12 WSYZ optymalizacja sieciowa

Czym różni się system agentowy od systemu aktorów?	<b>SYSTEM AGENTOWY</b><br>• Agent = autonomiczny, reaktywny, proaktywny, społeczny<br>• Architektura BDI (Beliefs-Desires-Intentions)<br>• Komunikacja: FIPA-ACL (semantyka, performatywy)<br>• Cel: symulacja, AI, negocjacje<br>• Przykład: JADE, Jason<br><br><b>SYSTEM AKTORÓW</b><br>• Aktor = lekka jednostka obliczeniowa<br>• Komunikacja: asynchroniczne wiadomości (fire-and-forget)<br>• Brak stanu współdzielonego (share nothing)<br>• Cel: współbieżność, skalowalność, fault-tolerance<br>• Przykład: Akka, Erlang/OTP<br><br><b>Kluczowa różnica:</b><br>Agent = inteligentny, autonomiczny, ma cele<br>Aktor = jednostka obliczeniowa, reaktywna, bez "inteligencji"	pyt13 ISA agenty_aktorzy

Co to jest architektura BDI w systemach agentowych?	<b>BDI = Beliefs-Desires-Intentions</b><br><br><b>Beliefs (Przekonania)</b><br>Co agent wie o świecie<br>Baza wiedzy, może być niepełna/błędna<br><br><b>Desires (Pragnienia)</b><br>Cele, które agent chce osiągnąć<br>Mogą być sprzeczne ze sobą<br><br><b>Intentions (Intencje)</b><br>Wybrane cele, do których agent się zobowiązał<br>Plany działania<br><br><b>Cykl decyzyjny:</b><br>1. Percepcja → aktualizuj Beliefs<br>2. Generuj opcje (desires)<br>3. Deliberacja → wybierz intentions<br>4. Wykonaj plan<br>5. Powtórz<br><br><b>Zastosowania:</b> robotyka, symulacja zachowań, gry	pyt13 ISA bdi agenty

Jakie są algorytmy koordynacji w systemach wieloagentowych?	<b>1. Contract Net Protocol (CNET)</b><br>Manager ogłasza zadanie → Agenty składają oferty → Wybór najlepszej<br>Zastosowanie: alokacja zadań<br><br><b>2. Aukcje wieloagentowe</b><br>• Angielska (rosnąca), holenderska (malejąca)<br>• Vickrey (druga cena) - zachęca do prawdziwych ofert<br>• Kombinatoryczne - pakiety zasobów<br><br><b>3. Protokoły konsensusu</b><br>Agenty uzgadniają wspólną wartość<br>ẋᵢ = Σⱼ aᵢⱼ(xⱼ - xᵢ) → zbieżność do średniej<br><br><b>4. Multi-Agent Reinforcement Learning</b><br>• Independent Q-learning<br>• Cooperative/Competitive<br>• Emergent behavior	pyt14 ISA wieloagentowe koordynacja

Co to jest framework TOGAF w modelowaniu architektury?	<b>TOGAF = The Open Group Architecture Framework</b><br><br><b>ADM (Architecture Development Method):</b><br>Cykliczny proces 8 faz:<br>1. Preliminary - przygotowanie<br>2. Vision - wizja architektury<br>3. Business Architecture - procesy biznesowe<br>4. IS Architecture - dane + aplikacje<br>5. Technology Architecture - infrastruktura<br>6. Opportunities & Solutions - planowanie migracji<br>7. Migration Planning - szczegółowy plan<br>8. Governance - zarządzanie zmianami<br><br><b>4 domeny architektury:</b><br>• Business, Data, Application, Technology (BDAT)<br><br><b>Praktyka:</b> Standard korporacyjny, duże organizacje	pyt15 ISA togaf architektura

Porównaj wzorce architektoniczne: Layers, Microservices, Event-Driven.	<b>LAYERS (Warstwowa)</b><br>Prezentacja → Logika → Dane<br>✓ Prostota, separacja<br>✗ Monolityczna, trudna skalowalność<br><br><b>MICROSERVICES</b><br>Małe, niezależne serwisy<br>✓ Skalowalność, niezależny deployment<br>✓ Różne technologie<br>✗ Złożoność operacyjna, distributed transactions<br>Wymaga: API Gateway, Service Discovery<br><br><b>EVENT-DRIVEN (EDA)</b><br>Komponenty komunikują się przez zdarzenia<br>✓ Luźne powiązania, reaktywność<br>✓ Skalowalność, CQRS/Event Sourcing<br>✗ Trudne debugowanie, eventual consistency<br>Wymaga: Message Broker (Kafka, RabbitMQ)<br><br><b>Praktyka:</b> Często łączone (microservices + events)	pyt16 ISA wzorce_architektoniczne

Jakie są warunki KKT w optymalizacji nieliniowej?	<b>KKT = Karush-Kuhn-Tucker</b><br><br>Dla problemu: min f(x), g(x) ≤ 0, h(x) = 0<br><br><b>Warunki konieczne optimum:</b><br><br>1. <b>Stacjonarność:</b><br>∇f(x*) + Σμᵢ∇gᵢ(x*) + Σλⱼ∇hⱼ(x*) = 0<br><br>2. <b>Dopuszczalność pierwotna:</b><br>g(x*) ≤ 0, h(x*) = 0<br><br>3. <b>Dopuszczalność dualna:</b><br>μᵢ ≥ 0 (dla ograniczeń nierównościowych)<br><br>4. <b>Complementary slackness:</b><br>μᵢ · gᵢ(x*) = 0 (aktywne lub μ=0)<br><br><b>Dla wypukłych:</b> KKT są wystarczające!<br><b>Dla niewypukłych:</b> tylko konieczne (lokalne opt.)	pyt17 MOM kkt optymalizacja_nieliniowa

Czym różni się metoda simpleks od interior point?	<b>METODA SIMPLEKS</b><br>• Porusza się po wierzchołkach wielościanu<br>• Iteracja: przejście do lepszego sąsiada<br>• Złożoność: O(2ⁿ) pesymistycznie<br>• W praktyce: bardzo szybka dla większości problemów<br>• Problemy zdegenerowane: cycling<br><br><b>INTERIOR POINT (bariery)</b><br>• Porusza się WEWNĄTRZ wielościanu<br>• Zbliża się do granicy przy optimum<br>• Złożoność: wielomianowa O(n³·L)<br>• Lepsza dla bardzo dużych problemów<br>• Wymaga więcej pamięci<br><br><b>Praktyka:</b><br>Simplex: małe/średnie LP, basis info<br>Interior Point: duże LP, QP, SDP	pyt18 MOM simplex lp

Jak działa parametryzacja MFCC w rozpoznawaniu mowy?	<b>MFCC = Mel-Frequency Cepstral Coefficients</b><br><br><b>Pipeline przetwarzania:</b><br>1. <b>Pre-emphasis:</b> y[n] = x[n] - αx[n-1] (wzmocnienie wysokich częstotliwości)<br>2. <b>Ramkowanie:</b> okna 20-40ms z overlap<br>3. <b>FFT:</b> spektrum częstotliwościowe<br>4. <b>Mel filterbank:</b> 26-40 filtrów w skali mel (nieliniowa, jak ucho)<br>5. <b>Log:</b> logarytm energii filtrów<br>6. <b>DCT:</b> 12-13 współczynników cepstralnych<br><br><b>Rozszerzenia:</b><br>• Δ (pierwsza pochodna) - dynamika<br>• ΔΔ (druga pochodna)<br>• Razem: 39 cech (13 + 13 + 13)<br><br><b>Dlaczego mel?</b> Ucho słyszy nieliniowo - różnice w niskich częstotliwościach ważniejsze	pyt19 RUM mfcc parametryzacja_mowy

Porównaj HMM i Deep Learning w rozpoznawaniu mowy.	<b>HMM (Hidden Markov Model)</b><br>• Stany ukryte → emisje (GMM)<br>• Algorytmy: Viterbi, Forward-Backward, Baum-Welch<br>• Zalety: interpretowalność, mało danych<br>• Wady: założenie Markowa, ręczne features<br><br><b>DNN-HMM (Hybrid)</b><br>• DNN zastępuje GMM do modelowania emisji<br>• HMM nadal modeluje sekwencję<br>• Breakthrough: 2012 (Hinton et al.)<br><br><b>End-to-End Deep Learning</b><br>• CTC (Connectionist Temporal Classification)<br>• Attention/Transformer (Seq2Seq)<br>• Brak alignmentu, brak HMM<br>• Przykłady: DeepSpeech, Whisper<br><br><b>Praktyka 2024:</b> Transformery dominują (Whisper, Wav2Vec)	pyt20 RUM hmm deep_learning mowa

Co to jest agent upostaciowiony (embodied agent)?	<b>Embodied Agent = agent z "ciałem" w fizycznym świecie</b><br><br>Różnica od agenta symulowanego:<br>• Interakcja z rzeczywistym środowiskiem<br>• Sensory: kamery, LIDAR, enkodery<br>• Efektory: silniki, chwytaki<br>• Niepewność: szum, opóźnienia, awarie<br><br><b>Architektura (typowa):</b><br>1. Percepcja: sensory → model świata<br>2. Planowanie: cel → sekwencja akcji<br>3. Wykonanie: akcje → efektory<br>4. Feedback: monitorowanie i korekta<br><br><b>Frameworki:</b><br>• ROS (Robot Operating System)<br>• BDI dla robotów (Jason + ROS)<br><br><b>Wyzwania:</b><br>• Real-time constraints<br>• Niepewność percepcji<br>• Bezpieczeństwo (safety-critical)	pyt21 SIU embodied_agent roboty

Jakie są poziomy języków programowania robotów?	<b>Hierarchia (od wysokiego do niskiego):</b><br><br>1. <b>Task Level</b> (najwyższy)<br>"Zmontuj produkt A" - planowanie zadań<br>AI, reasoning<br><br>2. <b>Robot Level</b><br>Ruchy w przestrzeni kartezjańskiej<br>Ścieżki, trajektorie end-effector<br><br>3. <b>Motion Level</b><br>Kinematyka, trajektorie stawów<br>Planowanie ruchu (RRT, A*)<br><br>4. <b>Servo Level</b> (najniższy)<br>Sterowanie silnikami<br>PID, kontrola pozycji/prędkości<br><br><b>Języki przemysłowe:</b><br>• RAPID (ABB)<br>• KRL (KUKA)<br>• Karel (FANUC)<br>• URScript (Universal Robots)<br><br><b>Standardy:</b> IEC 61131-3 (PLC), ROS (research)	pyt22 SIU jezyki_robotow programowanie

Jak działają zegary logiczne Lamporta?	<b>Problem:</b> Brak globalnego zegara w systemach rozproszonych<br><br><b>Algorytm:</b><br>Każdy proces Pᵢ ma licznik Cᵢ:<br>1. Przed zdarzeniem lokalnym: Cᵢ++<br>2. Wysyłanie msg: Cᵢ++, dołącz timestamp<br>3. Odbiór msg z timestamp t: Cᵢ = max(Cᵢ, t) + 1<br><br><b>Właściwości:</b><br>✓ a → b ⟹ C(a) < C(b) (porządek zachowany)<br>✗ C(a) < C(b) ⟹ a → b (NIE! mogą być współbieżne)<br><br><b>Zegary wektorowe:</b><br>Wektor V[1..N] dla N procesów<br>V[i] = wiedza procesu o wszystkich<br>a → b ⟺ V(a) < V(b) (obustronna implikacja!)<br><br><b>Zastosowanie:</b> Causal ordering, wykrywanie współbieżności	pyt23 ERSMS zegary_logiczne lamport

Czym różni się linearizability od eventual consistency?	<b>LINEARIZABILITY (najsilniejsza)</b><br>• Operacja wygląda jakby wykonała się atomowo<br>• "Globalny porządek czasu rzeczywistego"<br>• Wynik natychmiast widoczny wszędzie<br>• Kosztowna: wymaga koordynacji (Paxos, Raft)<br>• Przykład: transakcje bankowe<br><br><b>EVENTUAL CONSISTENCY (najsłabsza)</b><br>• "Ostatecznie wszystkie repliki się zsynchronizują"<br>• Brak gwarancji kiedy<br>• Możliwe stare odczyty<br>• Wysoka dostępność (AP w CAP)<br>• Przykład: DNS, caching, social media feeds<br><br><b>Pomiędzy:</b><br>• Sequential: globalny porządek, nie real-time<br>• Causal: porządek przyczynowy zachowany	pyt24 ERSMS spojnosc consistency

Co to jest Branch and Bound i jak działa?	<b>Branch and Bound = metoda dokładna dla MIP</b><br><br><b>Idea:</b><br>1. Relaksacja LP: rozwiąż bez ograniczeń całkowitoliczbowych<br>2. Jeśli rozwiązanie całkowite → STOP<br>3. BRANCH: wybierz zmienną ułamkową xᵢ<br>4. Utwórz 2 podproblemy: xᵢ ≤ ⌊x*ᵢ⌋ i xᵢ ≥ ⌈x*ᵢ⌉<br>5. BOUND: jeśli LP ≤ best known → prune<br><br><b>Przycinanie (pruning):</b><br>• Infeasible: brak rozwiązania LP<br>• Optimality: LP ≤ incumbent<br>• Integrality: znalezione całkowite<br><br><b>Strategie wyboru węzła:</b><br>• Best-first (najlepsze ograniczenie)<br>• Depth-first (mniej pamięci)<br>• Best-estimate (heurystyka)	pyt25 MOD branch_and_bound mip

Jakie są główne narzędzia do optymalizacji dyskretnej?	<b>SOLVERY MIP (komercyjne):</b><br>• CPLEX (IBM) - najszybszy<br>• Gurobi - bardzo szybki, dobre API<br><br><b>SOLVERY MIP (open source):</b><br>• SCIP - framework rozszerzalny<br>• CBC (COIN-OR) - dobry darmowy<br>• HiGHS - nowoczesny<br><br><b>CONSTRAINT PROGRAMMING:</b><br>• CP-SAT (Google OR-Tools) - bardzo szybki<br>• Gecode - akademicki<br>• MiniZinc - język modelowania<br><br><b>JĘZYKI MODELOWANIA:</b><br>• Pyomo (Python)<br>• JuMP (Julia)<br>• AMPL, GAMS (komercyjne)<br><br><b>Kiedy CP vs MIP?</b><br>CP: scheduling, alldifferent, kombinatoryczne<br>MIP: silna relaksacja LP, ciągłe zmienne	pyt26 MOD solvery narzedzia

Dlaczego jakość modelu danych jest krytyczna?	<b>Model danych = fundament systemu</b><br>Zmiana modelu → kaskadowe zmiany wszędzie<br><br><b>Konsekwencje złego modelu:</b><br><br>1. <b>Wydajność:</b><br>JOIN na stringach vs integer PK/FK<br>Brak indeksów, denormalizacja → full scans<br><br>2. <b>Spójność:</b><br>Redundancja → anomalie (insert, update, delete)<br>Brak constraints → nieprawidłowe dane<br><br>3. <b>Utrzymywalność:</b><br>Niezrozumiałe nazwy (col1, temp_field)<br>Brak dokumentacji ERD<br><br>4. <b>Koszty naprawy:</b><br>Analiza: tanie<br>Design: średnie<br>Implementacja: drogie<br>Produkcja: BARDZO drogie (migracje!)	pyt27 MODA model_danych jakosc

Jakie są fazy ewolucji modelu danych?	<b>1. KONCEPTUALNY (CDM)</b><br>• CO przechowujemy (biznes)<br>• Zrozumiały dla nietechnicznych<br>• Encje i relacje (brak atrybutów szczegółowych)<br>• ERD uproszczony<br><br><b>2. LOGICZNY (LDM)</b><br>• JAK strukturyzujemy<br>• Atrybuty, typy logiczne, klucze PK/FK<br>• Normalizacja (min 3NF)<br>• Niezależny od DBMS<br><br><b>3. FIZYCZNY (PDM)</b><br>• JAK implementujemy<br>• Typy danych specyficzne dla DBMS<br>• Indeksy, partycjonowanie, tablespaces<br>• Optymalizacja wydajności<br><br><b>Transformacja:</b><br>CDM → LDM: dodaj atrybuty, normalizuj<br>LDM → PDM: dostosuj do DBMS, zoptymalizuj	pyt28 MODA fazy_modelu ewolucja

Co mówi prawo Amdahla o przyśpieszeniu równoległym?	<b>Formuła Amdahla:</b><br>S(n) = 1 / [(1-p) + p/n]<br><br>Gdzie:<br>• p = część równoległa (0-1)<br>• n = liczba procesorów<br>• (1-p) = część sekwencyjna<br><br><b>Maksymalne przyśpieszenie (n→∞):</b><br>S_max = 1/(1-p)<br><br><b>Przykład:</b><br>90% równoległe (p=0.9):<br>S_max = 1/0.1 = 10x<br>Nawet z nieskończoną liczbą CPU!<br><br><b>Wniosek:</b> Część sekwencyjna LIMITUJE przyśpieszenie<br><br><b>Prawo Gustafsona:</b> Skaluj problem, nie przyśpieszenie<br>S_scaled = 1 - p + p·n (liniowe z n!)	pyt29 PORR amdahl rownolegle

Jakie są etapy tworzenia modelu optymalizacyjnego?	<b>1. ANALIZA PROBLEMU</b><br>• Zrozum dziedzinę biznesową<br>• Zidentyfikuj decyzje, cele, ograniczenia<br><br><b>2. ZMIENNE DECYZYJNE</b><br>• Co kontrolujemy? (x, y, z...)<br>• Typy: ciągłe, całkowite, binarne<br>• Zmienne muszą być mierzalne i kontrolowalne<br><br><b>3. FUNKCJA CELU</b><br>• min/max f(x)<br>• Co optymalizujemy? (koszt, zysk, czas)<br><br><b>4. OGRANICZENIA</b><br>• g(x) ≤ 0, h(x) = 0<br>• Zasoby, fizyka, logika biznesowa<br><br><b>5. WALIDACJA</b><br>• Extreme cases<br>• Known solutions<br>• Analiza wrażliwości<br><br><b>Problemy:</b> Big-M (słaba relaksacja), symetria	pyt30 MOM modelowanie optymalizacja

Dlaczego wypukłość jest ważna w optymalizacji?	<b>Problem wypukły:</b><br>• min f(x) gdzie f wypukła<br>• Ograniczenia definiują zbiór wypukły<br><br><b>Kluczowa właściwość:</b><br>LOKALNE optimum = GLOBALNE optimum<br><br><b>Konsekwencje:</b><br>1. Gwarancja znalezienia najlepszego rozwiązania<br>2. Algorytmy wielomianowe (interior point)<br>3. Silna dualność (zero gap)<br>4. KKT wystarczające (nie tylko konieczne)<br><br><b>Niewypukłe problemy:</b><br>• Wiele minimów lokalnych<br>• NP-trudne<br>• Tylko lokalne optimum (gradient, Newton)<br>• Metaheurystyki: SA, GA (bez gwarancji)<br><br><b>Praktyka:</b> Przekształć w wypukły jeśli możliwe!	pyt31 MOM wypuklosc optymalizacja

Różnica między komunikacją blokującą a nieblokującą w MPI.	<b>BLOKUJĄCA</b><br>• MPI_Send, MPI_Recv<br>• Zwraca gdy operacja "zakończona"<br>• Bufor można bezpiecznie użyć ponownie<br>• Ryzyko deadlocka przy złej kolejności<br><br><b>NIEBLOKUJĄCA</b><br>• MPI_Isend, MPI_Irecv<br>• Zwraca natychmiast (request handle)<br>• Operacja w tle<br>• MPI_Wait/MPI_Test do sprawdzenia<br>• Overlapping: obliczenia + komunikacja<br><br><b>Deadlock example:</b><br>P0: Send(to=1); Recv(from=1);<br>P1: Send(to=0); Recv(from=0);<br>→ Oba czekają na recv, nikt nie wysyła<br><br><b>Rozwiązanie:</b> MPI_Sendrecv lub nieblokujące	pyt32 PORR mpi blokujace

Jak działa model Publish-Subscribe?	<b>Architektura:</b><br>PUBLISHERS → BROKER → SUBSCRIBERS<br><br><b>Cechy:</b><br>• Luźne powiązanie (publisher nie zna subscriberów)<br>• Asynchroniczność<br>• Skalowalność 1:N, N:M<br><br><b>Typy subskrypcji:</b><br>• Topic-based: subscribe("orders")<br>• Content-based: price > 100<br>• Hierarchical: home/+/temperature (wildcards)<br><br><b>QoS (Quality of Service):</b><br>• QoS 0: at most once (fire-and-forget)<br>• QoS 1: at least once (możliwe duplikaty)<br>• QoS 2: exactly once (4-way handshake)<br><br><b>Implementacje:</b><br>• Apache Kafka (log-based, high throughput)<br>• RabbitMQ (AMQP, flexible routing)<br>• MQTT (IoT, lightweight)	pyt33 PSD pub_sub messaging

Czym charakteryzuje się przetwarzanie danych strumieniowych?	<b>Strumień vs Batch:</b><br>• Unbounded (nieskończony)<br>• Ciągłe napływanie danych<br>• Wymagana niska latencja<br>• Brak możliwości przechowania wszystkiego<br><br><b>Windowing (okna czasowe):</b><br>• Tumbling: rozłączne, stała wielkość<br>• Sliding: nakładające się<br>• Session: oparte na aktywności<br>• Global: jedno okno, trigger decyduje<br><br><b>Event Time vs Processing Time:</b><br>• Event time: kiedy zdarzenie nastąpiło<br>• Processing time: kiedy dotarło<br>• Watermark: znacznik postępu event time<br><br><b>Platformy:</b><br>• Apache Flink (stateful, exactly-once)<br>• Kafka Streams (library, Kafka ecosystem)<br>• Apache Spark Streaming (micro-batch)	pyt34 PSD streaming analityka

Co to są systemy cyber-fizyczne (CPS)?	<b>CPS = Cyber + Physical w pętli sprzężenia</b><br><br><b>Komponenty:</b><br>• Cyber: obliczenia, komunikacja, sterowanie<br>• Physical: dynamika, fizyka, środowisko<br>• Sensors + Actuators = połączenie<br><br><b>Specyfika modelowania:</b><br>• Hybrid systems: ciągłe ODE + dyskretne automaty<br>• Real-time constraints<br>• Niepewność, szum, opóźnienia<br><br><b>Przykład - termostat:</b><br>Mode OFF: Ṫ = -α(T-Tₑ)<br>Mode ON: Ṫ = β - α(T-Tₑ)<br>Przełączanie: T<Tₗ → ON, T>Tₕ → OFF<br><br><b>Consensus w sieci agentów:</b><br>ẋᵢ = Σⱼ aᵢⱼ(xⱼ - xᵢ) → zbieżność do średniej<br><br><b>Przykłady:</b> autonomiczne pojazdy, smart grid, Industry 4.0	pyt35 SIU cps cyber_fizyczne

Jakie są elementy uczenia ze wzmocnieniem?	<b>Model RL:</b><br>Agent ↔ Environment<br>Agent: akcja aₜ → Environment<br>Environment: stan sₜ₊₁, nagroda rₜ → Agent<br><br><b>Elementy:</b><br>• State (s): obserwacja środowiska<br>• Action (a): decyzja agenta<br>• Reward (r): sygnał zwrotny<br>• Policy π(a|s): strategia<br>• Value V(s), Q(s,a): oczekiwana nagroda<br>• Discount γ: ważność przyszłych nagród<br><br><b>MDP (Markov Decision Process):</b><br>P(sₜ₊₁|sₜ,aₜ) - tylko obecny stan ma znaczenie<br><br><b>Algorytmy:</b><br>• Value-based: Q-learning, DQN<br>• Policy-based: REINFORCE, PPO<br>• Actor-Critic: A2C, A3C, SAC<br><br><b>Cel:</b> max E[Σ γᵗrₜ]	pyt36 SIU rl uczenie_wzmocnienie

Porównaj modele sieci złożonych: ER, Watts-Strogatz, Barabási-Albert.	<b>ERDŐS-RÉNYI (Random)</b><br>G(n,p) - krawędź z prawdop. p<br>• Rozkład stopni: Poisson<br>• Niski clustering C=p<br>• Krótka ścieżka L~log(n)<br>• Brak hubów<br><br><b>WATTS-STROGATZ (Small-World)</b><br>Regularna kratka + losowe przepinanie<br>• Wysoki clustering (zachowany)<br>• Krótka ścieżka (dodana)<br>• "6 degrees of separation"<br><br><b>BARABÁSI-ALBERT (Scale-Free)</b><br>Preferential attachment (rich-get-richer)<br>• Rozkład: power-law P(k)~k⁻ᵞ<br>• Huby (węzły o bardzo wysokim stopniu)<br>• Odporność na losowe awarie<br>• Wrażliwość na celowane ataki<br><br><b>Rzeczywiste sieci:</b> cechy BA + WS (huby + clustering)	pyt37 TASS sieci_zlozone modele

Co to jest projekcja grafu dwudzielnego?	<b>Graf dwudzielny:</b><br>Dwa rozłączne zbiory U, V<br>Krawędzie tylko między U i V<br>Przykład: dokumenty ↔ słowa<br><br><b>Projekcja:</b><br>Przekształcenie na graf jednomodowy<br>P = B·Bᵀ (projekcja na U)<br>Węzły U połączone jeśli mają wspólnego sąsiada w V<br><br><b>Metody ważenia krawędzi:</b><br>• Simple count: |N(i) ∩ N(j)|<br>• Jaccard: |∩| / |∪|<br>• Cosine: dot product / normy<br>• TF-IDF: rzadkie słowa ważniejsze<br><br><b>Zastosowanie - grupowanie dokumentów:</b><br>1. Graf: dokumenty ↔ słowa<br>2. TF-IDF weights<br>3. Projekcja na dokumenty<br>4. Clustering na projekcji	pyt38 TASS projekcje grafy_dwudzielne

Jakie są metody segmentacji obrazu?	<b>KLASYCZNE:</b><br><br>1. <b>Thresholding:</b> Otsu (automatyczny próg)<br>2. <b>Region Growing:</b> seed → ekspansja po podobnych<br>3. <b>Watershed:</b> obraz jako topografia, zalewanie<br>4. <b>Graph-based:</b> Normalized Cuts, Laplacian<br><br><b>DEEP LEARNING:</b><br><br>1. <b>FCN (Fully Convolutional):</b><br>Brak FC layers → dowolny rozmiar wejścia<br><br>2. <b>U-Net:</b><br>Encoder-decoder + skip connections<br>Świetne dla małych datasetów (medycyna)<br><br>3. <b>DeepLab:</b><br>Atrous/dilated convolutions<br>ASPP (multi-scale)<br><br><b>Typy segmentacji:</b><br>• Semantic: klasa dla piksela<br>• Instance: rozróżnia instancje<br>• Panoptic: unified (semantic + instance)	pyt39 TWM segmentacja cv

Jak działa detekcja obiektów (klasyczne vs deep learning)?	<b>KLASYCZNE:</b><br><br>1. <b>Sliding Window + HOG/SIFT:</b><br>Przesuwaj okno, klasyfikuj fragment<br>Problem: O(scales × positions) - WOLNE<br><br>2. <b>Viola-Jones (2001):</b><br>Haar features + AdaBoost cascade<br>Integral image → O(1) per feature<br>Real-time face detection<br><br><b>DEEP LEARNING:</b><br><br>1. <b>Two-stage (R-CNN family):</b><br>Region proposals → CNN → classify<br>Faster R-CNN: RPN (learned proposals)<br><br>2. <b>One-stage:</b><br>YOLO: grid cells, predict directly<br>SSD: multi-scale feature maps<br>Szybsze, mniej dokładne<br><br><b>Metryki:</b> mAP (mean Average Precision), IoU	pyt40 TWM detekcja_obiektow cv

Co to jest dominacja stochastyczna pierwszego i drugiego rzędu?	<b>FSD (First-order Stochastic Dominance):</b><br>A ≥_FSD B ⟺ F_A(x) ≤ F_B(x) dla wszystkich x<br><br>• A "zawsze lepsze" od B<br>• KAŻDY racjonalny decydent (U'≥0) wybierze A<br>• Najsilniejsza, rzadko występuje<br><br><b>SSD (Second-order):</b><br>A ≥_SSD B ⟺ ∫F_A(t)dt ≤ ∫F_B(t)dt dla wszystkich x<br><br>• Dla decydentów risk-averse (U'≥0, U''≤0)<br>• Słabsza niż FSD, częstsza<br>• CDF mogą się przecinać, ale skumulowane pole - nie<br><br><b>Zastosowanie:</b><br>Porównanie portfeli/loterii BEZ znajomości dokładnej funkcji użyteczności<br>FSD/SSD → eliminacja zdominowanych opcji	pyt42 WDWR dominacja_stochastyczna

Jak klasyfikuje się zadania szeregowania (notacja Grahama)?	<b>Notacja: α | β | γ</b><br><br><b>α - Środowisko maszynowe:</b><br>• 1: jedna maszyna<br>• Pm: m maszyn równoległych<br>• Fm: flow shop z m maszynami<br>• Jm: job shop z m maszynami<br><br><b>β - Charakterystyki zadań:</b><br>• rⱼ: release dates<br>• dⱼ: due dates<br>• prec: precedence constraints<br>• pmtn: preemption allowed<br>• pⱼ=1: unit processing times<br><br><b>γ - Kryterium:</b><br>• Cmax: makespan (max completion)<br>• ΣCⱼ: total completion time<br>• Lmax: max lateness<br>• ΣTⱼ: total tardiness<br><br><b>Przykład:</b> 1|rⱼ|Lmax - jedna maszyna, release dates, minimalizuj max spóźnienie	pyt43 ZBOP szeregowanie scheduling

Co to jest efekt byczego bicza (bullwhip effect)?	<b>Bullwhip Effect = amplifikacja wahań popytu w górę łańcucha dostaw</b><br><br><b>Mechanizm:</b><br>Mały popyt klienta → większe wahania detalisty → jeszcze większe dystrybutora → ogromne u producenta<br><br><b>Przyczyny:</b><br>1. Prognozowanie popytu (każdy poziom dodaje safety stock)<br>2. Batching zamówień (nie zamawiaj po 1 sztuce)<br>3. Wahania cen (promocje → stockpiling)<br>4. Rationing (przy niedoborze zawyżanie zamówień)<br><br><b>Konsekwencje:</b><br>• Nadmiar zapasów lub stockouts<br>• Nieefektywna produkcja<br>• Wysokie koszty<br><br><b>Rozwiązania:</b><br>• Współdzielenie informacji (VMI, CPFR)<br>• Everyday Low Price (brak promocji)<br>• Smaller batches	pyt44 ZBOP bullwhip lancuch_dostaw

Co to jest model EOQ i jakie ma założenia?	<b>EOQ = Economic Order Quantity</b><br><br><b>Formuła:</b><br>Q* = √(2KD/h)<br><br>Gdzie:<br>• K = koszt zamówienia (stały)<br>• D = roczny popyt<br>• h = koszt utrzymania jednostki/rok<br><br><b>Założenia:</b><br>• Popyt stały i znany<br>• Lead time stały i znany<br>• Natychmiastowa dostawa<br>• Brak braków (stockouts)<br>• Brak rabatów ilościowych<br><br><b>Całkowity koszt:</b><br>TC = (K × D/Q) + (h × Q/2)<br>Ordering cost + Holding cost<br><br><b>W praktyce:</b> Punkt bazowy, modyfikowany dla:<br>• Losowy popyt → safety stock<br>• Lead time → reorder point<br>• Rabaty → quantity discounts model	pyt44 ZBOP eoq zapasy

