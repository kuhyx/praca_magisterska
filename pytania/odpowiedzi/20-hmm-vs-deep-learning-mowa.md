# Pytanie 20: Rozpoznawanie mowy - HMM vs Deep Learning

## Pytanie
**"PrzedstawiÄ‡ klasycznÄ… metodÄ™ rozpoznawania mowy opartÄ… o HMM (Ukryte Modele Markowa). PorÃ³wnaÄ‡ jÄ… z metodami korzystajÄ…cymi z gÅ‚Ä™bokich sieci neuronowych."**

Przedmiot: EASAR (Elementy Automatycznego Sterowania i Rozpoznawania)

---

## ğŸ“š OdpowiedÅº gÅ‚Ã³wna

### 1. System rozpoznawania mowy - architektura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SygnaÅ‚ audio                                                   â”‚
â”‚      â†“                                                          â”‚
â”‚  [Ekstrakcja cech] â”€â”€â†’ MFCC/Filterbanks                        â”‚
â”‚      â†“                                                          â”‚
â”‚  [Model akustyczny] â”€â”€â†’ HMM / DNN / Hybrid                     â”‚
â”‚      â†“                                                          â”‚
â”‚  [Model jÄ™zykowy] â”€â”€â†’ N-gram / RNN-LM                          â”‚
â”‚      â†“                                                          â”‚
â”‚  [Dekoder] â”€â”€â†’ Wyszukiwanie najlepszej hipotezy                â”‚
â”‚      â†“                                                          â”‚
â”‚  Tekst                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2. HMM (Hidden Markov Model) - klasyczne podejÅ›cie

#### Struktura HMM dla fonemu

```
      aâ‚â‚‚         aâ‚‚â‚ƒ         aâ‚ƒâ‚„
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â†’
  â”‚          â”‚          â”‚
â”Œâ”€â”´â”€â”      â”Œâ”€â”´â”€â”      â”Œâ”€â”´â”€â”      â”Œâ”€â”€â”€â”
â”‚ 1 â”‚      â”‚ 2 â”‚      â”‚ 3 â”‚      â”‚ 4 â”‚
â”‚   â”‚      â”‚   â”‚      â”‚   â”‚      â”‚ENDâ”‚
â””â”€â”¬â”€â”˜      â””â”€â”¬â”€â”˜      â””â”€â”¬â”€â”˜      â””â”€â”€â”€â”˜
  â”‚          â”‚          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     aâ‚â‚        aâ‚‚â‚‚        aâ‚ƒâ‚ƒ (self-loops)

KaÅ¼dy stan emituje obserwacje (MFCC) wedÅ‚ug rozkÅ‚adu GMM:
b_j(o) = Î£_m c_{jm} N(o; Î¼_{jm}, Î£_{jm})
```

#### Parametry HMM

| Symbol | Opis |
|--------|------|
| **A** | Macierz przejÅ›Ä‡ (a_ij) |
| **B** | RozkÅ‚ady emisji (GMM) |
| **Ï€** | RozkÅ‚ad poczÄ…tkowy |

#### Trzy problemy HMM

| Problem | Algorytm | Zastosowanie |
|---------|----------|--------------|
| **Ewaluacja:** P(O\|Î») | Forward-Backward | Scoring |
| **Dekodowanie:** argmax P(Q\|O) | Viterbi | Rozpoznawanie |
| **Uczenie:** argmax P(O\|Î») | Baum-Welch (EM) | Trening |

#### Algorytm Viterbi

```
ZnajdÅº najbardziej prawdopodobnÄ… sekwencjÄ™ stanÃ³w:

Î±_t(j) = max_{i} [Î±_{t-1}(i) Â· a_{ij}] Â· b_j(o_t)

Backtrace: Ïˆ_t(j) = argmax_{i} [Î±_{t-1}(i) Â· a_{ij}]

      t=1    t=2    t=3    t=4
s=1   â—â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â—
      â”‚â•²     â”‚â•²     â”‚â•²     â”‚
s=2   â—â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â—
      â”‚â•²     â”‚â•²     â”‚â•²     â”‚
s=3   â—â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â—
              Viterbi trellis
```

---

### 3. Deep Learning w rozpoznawaniu mowy

#### DNN-HMM Hybrid (2012+)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Klasyczne GMM-HMM:                                             â”‚
â”‚  Cechy MFCC â†’ GMM â†’ P(o|stan) â†’ HMM â†’ dekodowanie              â”‚
â”‚                                                                 â”‚
â”‚  Hybrid DNN-HMM:                                                â”‚
â”‚  Cechy â†’ DNN â†’ P(stan|o) â†’ P(o|stan) = P(stan|o)/P(stan)       â”‚
â”‚                    â†“                                            â”‚
â”‚                   HMM â†’ dekodowanie                             â”‚
â”‚                                                                 â”‚
â”‚  DNN zastÄ™puje GMM jako model emisji!                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### End-to-End Models (2014+)

```
CTC (Connectionist Temporal Classification):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Audio â†’ [LSTM/Transformer] â†’ P(y_t|x) â†’ CTC Loss â†’ Tekst    â”‚
â”‚                                                               â”‚
â”‚  CTC pozwala na rÃ³Å¼ne wyrÃ³wnania:                            â”‚
â”‚  "h-e-l-l-o" = "hh-ee-ll-lo" = "-h-e-l-l-o-"                â”‚
â”‚  (blank = '-')                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Attention-based (Seq2Seq):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Audio â†’ [Encoder] â†’ [Attention] â†’ [Decoder] â†’ Tekst         â”‚
â”‚                         â†“                                     â”‚
â”‚                   WyrÃ³wnanie uczone                          â”‚
â”‚                                                               â”‚
â”‚  Modele: LAS (Listen Attend Spell), Transformer ASR          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Transformer ASR (2020+)

```
Whisper, Wav2Vec 2.0, Conformer:

Audio waveform
     â†“
[CNN Feature Encoder]
     â†“
[Transformer Encoder] Ã— N
     â†“
[CTC / Attention Decoder]
     â†“
Tekst

Pre-training: Self-supervised na duÅ¼ych danych
Fine-tuning: Supervised na labeled data
```

---

### 4. PorÃ³wnanie HMM vs DNN

| Aspekt | GMM-HMM | DNN-HMM | End-to-End |
|--------|---------|---------|------------|
| **Model akustyczny** | GMM | DNN | DNN |
| **Model czasowy** | HMM | HMM | CTC/Attention |
| **WyrÃ³wnanie** | Viterbi | Viterbi | Uczone/CTC |
| **Trening** | EM (Baum-Welch) | Backprop | Backprop |
| **InterpretowalnoÅ›Ä‡** | Wysoka | Åšrednia | Niska |
| **Dane treningowe** | MaÅ‚e | Åšrednie | DuÅ¼e |
| **WER (Word Error Rate)** | ~15-20% | ~8-12% | ~3-5% |
| **Latencja** | Niska | Åšrednia | Zmienna |

---

### 5. Ewolucja wydajnoÅ›ci

```
WER na Switchboard (telefon):

Rok     Model              WER
2010    GMM-HMM           ~18%
2012    DNN-HMM           ~12%
2015    LSTM-HMM          ~8%
2017    LAS (Seq2Seq)     ~6%
2020    Conformer         ~4%
2023    Whisper Large     ~3%
        Poziom ludzki     ~4%
```

---

## ğŸ§  Mnemoniki

### "HMM = Hidden states + Markov + Model":
Ukryte stany, przejÅ›cia markowskie, emisje obserwacji

### "Viterbi = Find best path":
Dynamiczne programowanie dla najlepszej Å›cieÅ¼ki

### "CTC = Collapse The Characters":
Usuwa powtÃ³rzenia i blanki â†’ tekst

---

## â“ Pytania dodatkowe

### Q1: "Co to jest forced alignment?"
**OdpowiedÅº:** Viterbi z ograniczeniem do znanej transkrypcji. Wyznacza granice czasowe fonemÃ³w/sÅ‚Ã³w. UÅ¼ywane do tworzenia danych treningowych i TTS.

### Q2: "Dlaczego DNN jest lepszy od GMM?"
**OdpowiedÅº:** DNN moÅ¼e modelowaÄ‡ zÅ‚oÅ¼one, nieliniowe zaleÅ¼noÅ›ci. GMM zakÅ‚ada mieszaninÄ™ GaussianÃ³w (czÄ™sto niewystarczajÄ…ce). DNN korzysta z kontekstu (wiele ramek na wejÅ›ciu).

### Q3: "Co to jest language model fusion?"
**OdpowiedÅº:** ÅÄ…czenie modelu akustycznego z jÄ™zykowym: P(W|O) âˆ P(O|W)Â·P(W)^Î±. Shallow fusion (podczas dekodowania) lub deep fusion (wspÃ³lny trening).

---

## ğŸ¯ Kluczowe punkty

1. **HMM:** Stany ukryte, GMM emisje, Viterbi dekodowanie
2. **DNN-HMM Hybrid:** DNN zastÄ™puje GMM, HMM dla czasu
3. **End-to-End:** CTC lub Attention, bez HMM
4. **Trend:** WiÄ™ksze modele, wiÄ™cej danych, mniej inÅ¼ynierii cech

---

## ğŸ“– Å¹rÃ³dÅ‚a

1. Rabiner - "A Tutorial on HMM"
2. Hinton et al. - "Deep Neural Networks for Acoustic Modeling" (2012)
3. Graves et al. - "CTC" (2006)
4. Chan et al. - "LAS" (2016)
