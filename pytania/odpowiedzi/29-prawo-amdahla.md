# Pytanie 29: Prawo Amdahla - przyÅ›pieszenie programÃ³w rÃ³wnolegÅ‚ych

## Pytanie
**"OszacowaÄ‡ iloÅ›ciowo przyÅ›pieszenie wykonania programu sekwencyjnego z fragmentami rÃ³wnolegÅ‚ymi na maszynie wielordzeniowej. Co osÅ‚abia to ograniczenie?"**

Przedmiot: PORR (Programowanie RÃ³wnolegÅ‚e i Rozproszone)

---

## ğŸ“š OdpowiedÅº gÅ‚Ã³wna

### 1. Prawo Amdahla

#### FormuÅ‚a

$$S(n) = \frac{1}{(1-p) + \frac{p}{n}}$$

Gdzie:
- $S(n)$ = przyÅ›pieszenie (speedup)
- $p$ = czÄ™Å›Ä‡ programu, ktÃ³ra moÅ¼e byÄ‡ zrÃ³wnoleglona (0 â‰¤ p â‰¤ 1)
- $n$ = liczba procesorÃ³w/rdzeni
- $(1-p)$ = czÄ™Å›Ä‡ sekwencyjna

#### Interpretacja graficzna

```
Czas wykonania:

Sekwencyjny (1 procesor):
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Sekwencyjna (1-p)     â”‚        RÃ³wnolegÅ‚a (p)            â”‚
â”‚          20%               â”‚              80%                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                        Tâ‚ = 100%

RÃ³wnolegÅ‚y (4 procesory):
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Sekwencyjna (1-p)     â”‚   RÃ³wnolegÅ‚a (p/n) â”‚
â”‚          20%               â”‚     80%/4 = 20%    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                        Tâ‚„ = 40%

Speedup = Tâ‚/Tâ‚„ = 100/40 = 2.5x
```

#### PrzykÅ‚ady liczbowe

| p (rÃ³wnolegÅ‚a) | n=2 | n=4 | n=8 | n=âˆ |
|----------------|-----|-----|-----|-----|
| 50% | 1.33 | 1.60 | 1.78 | 2.00 |
| 75% | 1.60 | 2.29 | 3.20 | 4.00 |
| 90% | 1.82 | 3.08 | 4.71 | 10.00 |
| 95% | 1.90 | 3.48 | 5.93 | 20.00 |
| 99% | 1.98 | 3.88 | 7.48 | 100.00 |

#### Maksymalne przyÅ›pieszenie (n â†’ âˆ)

$$S_{max} = \lim_{n \to \infty} S(n) = \frac{1}{1-p}$$

```
Dla p = 90% (10% sekwencyjnej):
S_max = 1/0.1 = 10x

Nawet z nieskoÅ„czonÄ… liczbÄ… procesorÃ³w,
10% kodu sekwencyjnego limituje speedup do 10x!
```

---

### 2. Wizualizacja ograniczenia

```
Speedup
   â†‘
20 â”¤                                    ........... p=99%
   â”‚                              ......
   â”‚                        ......
15 â”¤                   .....
   â”‚              .....
   â”‚          ....                       ______ p=95%
10 â”¤      ....                     _____/
   â”‚   ...                   _____/
   â”‚  ..              ______/              _____ p=90%
 5 â”¤ .          _____/               _____/
   â”‚.     _____/               _____/
   â”‚ ____/               _____/              ____ p=75%
 2 â”¼/           ________/_______________/____
 1 â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Procesory (n)
   1    4    8    16   32   64   128  256
```

**Obserwacja:** Krzywe szybko siÄ™ spÅ‚aszczajÄ… - dodawanie procesorÃ³w daje coraz mniejszy zysk.

---

### 3. Co osÅ‚abia ograniczenie Amdahla?

#### 3.1 Prawo Gustafsona-Barsisa (Scaled Speedup)

```
Amdahl: StaÅ‚y problem, wiÄ™cej procesorÃ³w
Gustafson: WiÄ™kszy problem, staÅ‚y czas

S_scaled(n) = n - (1-p)(n-1) = 1 - p + pÂ·n

Dla p = 90%, n = 100:
S_scaled = 1 - 0.9 + 0.9Â·100 = 90.1x (vs Amdahl: ~10x)

Zastosowanie: Symulacje, rendering, ML training
- WiÄ™kszy dataset
- WiÄ™cej iteracji
- WyÅ¼sza rozdzielczoÅ›Ä‡
```

#### 3.2 Techniki zmniejszania czÄ™Å›ci sekwencyjnej

| Technika | Opis |
|----------|------|
| **Algorytmy rÃ³wnolegÅ‚e** | Zamiana algorytmu sekwencyjnego na rÃ³wnolegÅ‚y |
| **Lock-free structures** | Unikanie synchronizacji blokujÄ…cej |
| **Pipelining** | NakÅ‚adanie faz obliczeÅ„ |
| **Speculative execution** | RÃ³wnolegÅ‚e wykonanie alternatyw |
| **Data parallelism** | PodziaÅ‚ danych zamiast zadaÅ„ |

#### 3.3 Ukrywanie latencji

```
Sekwencyjne I/O:
CPU: â”€â”€â”€â”€computeâ”€â”€â”€â”€â”‚waitâ”‚â”€â”€â”€â”€computeâ”€â”€â”€â”€â”‚waitâ”‚â”€â”€â”€â”€
                    â†‘ I/O               â†‘ I/O

Overlapping (prefetching, async I/O):
CPU: â”€â”€â”€â”€computeâ”€â”€â”€â”€â”€â”€â”€â”€computeâ”€â”€â”€â”€â”€â”€â”€â”€computeâ”€â”€â”€â”€
I/O:     â””â”€â”€fetchâ”€â”€â”˜   â””â”€â”€fetchâ”€â”€â”˜   â””â”€â”€fetchâ”€â”€â”˜

Efektywnie zmniejsza (1-p)!
```

---

### 4. Czynniki zmniejszajÄ…ce rzeczywiste przyÅ›pieszenie

```
S_real < S_Amdahl ze wzglÄ™du na:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. OVERHEAD SYNCHRONIZACJI                                      â”‚
â”‚    - Mutex, semaphore contention                               â”‚
â”‚    - Barrier wait time                                          â”‚
â”‚    - Lock granularity (coarse vs fine)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. KOMUNIKACJA                                                  â”‚
â”‚    - PrzesyÅ‚anie danych miÄ™dzy wÄ…tkami/procesami               â”‚
â”‚    - Bandwidth limitations                                      â”‚
â”‚    - Latency (szczegÃ³lnie distributed)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. LOAD IMBALANCE                                               â”‚
â”‚    - NierÃ³wny podziaÅ‚ pracy                                    â”‚
â”‚    - RÃ³Å¼ne czasy wykonania task'Ã³w                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. CACHE EFFECTS                                                â”‚
â”‚    - False sharing                                              â”‚
â”‚    - Cache coherency traffic                                   â”‚
â”‚    - NUMA effects                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. THREAD MANAGEMENT                                            â”‚
â”‚    - Tworzenie/niszczenie wÄ…tkÃ³w                               â”‚
â”‚    - Context switching                                          â”‚
â”‚    - Thread pool overhead                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### False Sharing

```c
// ZÅ‚y kod - false sharing
struct Counter {
    int count;  // Te pola sÄ… w tej samej linii cache!
} counters[NUM_THREADS];

// Thread i:
counters[i].count++;  // Invaliduje cache innych wÄ…tkÃ³w!

// Dobry kod - padding
struct Counter {
    int count;
    char padding[60];  // Separacja na osobne linie cache
} counters[NUM_THREADS];
```

---

### 5. EfektywnoÅ›Ä‡ rÃ³wnolegÅ‚a

$$E(n) = \frac{S(n)}{n} = \frac{1}{n \cdot (1-p) + p}$$

| p | n=4 | n=16 | n=64 |
|---|-----|------|------|
| 90% | 77% | 36% | 13% |
| 95% | 87% | 55% | 24% |
| 99% | 97% | 86% | 61% |

**Wniosek:** EfektywnoÅ›Ä‡ spada z liczbÄ… procesorÃ³w. Trzeba zwiÄ™kszaÄ‡ problem (Gustafson) lub zmniejszaÄ‡ (1-p).

---

### 6. Rozszerzone prawo Amdahla (z overhead)

$$S(n) = \frac{1}{(1-p) + \frac{p}{n} + O(n)}$$

Gdzie $O(n)$ = overhead zaleÅ¼ny od n (komunikacja, synchronizacja).

```
PrzykÅ‚ad: O(n) = 0.001Â·n (liniowy overhead)

n=10:   S = 1/(0.1 + 0.09 + 0.01) = 5.0
n=100:  S = 1/(0.1 + 0.009 + 0.1) = 4.8
n=1000: S = 1/(0.1 + 0.0009 + 1) = 0.9 (slowdown!)

Punkt optymalny: istnieje n* maksymalizujÄ…ce S!
```

---

## ğŸ§  Mnemoniki

### "Amdahl = Sequential is the limit":
CzÄ™Å›Ä‡ sekwencyjna limituje maksymalne przyÅ›pieszenie

### "S_max = 1/(1-p)":
10% sekwencyjnej â†’ max 10x speedup

### "Gustafson = Scale the problem":
WiÄ™kszy problem â†’ lepsze wykorzystanie procesorÃ³w

### "FLOP = False sharing, Load imbalance, Overhead, Poor locality":
GÅ‚Ã³wne przyczyny sublinearnego speedup

---

## â“ Pytania dodatkowe

### Q1: "Kiedy Gustafson jest lepszy od Amdahla?"
**OdpowiedÅº:** Gdy problem moÅ¼na skalowaÄ‡ (wiÄ™cej danych, iteracji). Symulacje fizyczne, rendering, ML training. Amdahl zakÅ‚ada staÅ‚y problem - pesymistyczny dla HPC.

### Q2: "Jak zmierzyÄ‡ rzeczywiste p?"
**OdpowiedÅº:** Profilowanie (perf, VTune). Zmierz czas sekwencyjny vs rÃ³wnolegÅ‚y. p â‰ˆ 1 - T_seq/T_total. Uwaga: p moÅ¼e zaleÅ¼eÄ‡ od danych wejÅ›ciowych.

### Q3: "Co to jest strong vs weak scaling?"
**OdpowiedÅº:** Strong: staÅ‚y problem, wiÄ™cej proc. (Amdahl). Weak: problem roÅ›nie proporcjonalnie do proc. (Gustafson). Weak scaling Å‚atwiejsze do osiÄ…gniÄ™cia.

---

## ğŸ¯ Kluczowe punkty

1. **Amdahl:** $S = 1/((1-p) + p/n)$, max = $1/(1-p)$
2. **Sekwencyjna czÄ™Å›Ä‡ limituje** - 10% seq â†’ max 10x
3. **Gustafson:** Skaluj problem, nie procesory
4. **Overhead:** Sync, komunikacja, cache, load imbalance
5. **EfektywnoÅ›Ä‡ spada** z liczbÄ… procesorÃ³w

---

## ğŸ“– Å¹rÃ³dÅ‚a

1. Amdahl - "Validity of the Single Processor Approach" (1967)
2. Gustafson - "Reevaluating Amdahl's Law" (1988)
3. Hennessy, Patterson - "Computer Architecture"
