# Pytanie 31: WypukÅ‚oÅ›Ä‡ i nieliniowoÅ›Ä‡ w systemach decyzyjnych

## Pytanie
**"WyjaÅ›niÄ‡ gÅ‚Ã³wne zagadnienia modelowania matematycznego w systemach decyzyjnych z wykorzystaniem pojÄ™Ä‡ (nie)wypukÅ‚oÅ›ci i (nie)liniowoÅ›ci."**

Przedmiot: MOM (Metody Optymalizacji Matematycznej)

---

## ğŸ“š OdpowiedÅº gÅ‚Ã³wna

### 1. Klasyfikacja problemÃ³w optymalizacyjnych

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KLASYFIKACJA PROBLEMÃ“W                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                 LINIOWE                    NIELINIOWE           â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚              â”‚     LP      â”‚            â”‚     NLP     â”‚        â”‚
â”‚              â”‚  Simplex,   â”‚            â”‚  Gradient,  â”‚        â”‚
â”‚              â”‚  Interior   â”‚            â”‚  Newton,    â”‚        â”‚
â”‚              â”‚  Point      â”‚            â”‚  SQP        â”‚        â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                â”‚                â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                    â”‚                       â”‚   â”‚
â”‚                              WYPUKÅE               NIEWYPUKÅE  â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                           â”‚ Convex NLP  â”‚      â”‚ Non-convex  â”‚ â”‚
â”‚                           â”‚ Global opt  â”‚      â”‚ Local opt   â”‚ â”‚
â”‚                           â”‚ gwarantowaneâ”‚      â”‚ NP-trudne   â”‚ â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2. Definicje kluczowe

#### ZbiÃ³r wypukÅ‚y

$$S \text{ wypukÅ‚y} \Leftrightarrow \forall x,y \in S, \forall \lambda \in [0,1]: \lambda x + (1-\lambda)y \in S$$

```
WYPUKÅY:                    NIEWYPUKÅY:
    â—â”€â”€â”€â”€â”€â”€â”€â—                  â—â”€â”€â”€â”€â”€â”€â”€â—
   /         \                /    â†—    \
  /           \              /   /       \
 /             \            /___/         \
â—               â—          â—               â—
  KaÅ¼dy odcinek              Odcinek wychodzi
  wewnÄ…trz zbioru            poza zbiÃ³r
```

#### Funkcja wypukÅ‚a

$$f \text{ wypukÅ‚a} \Leftrightarrow f(\lambda x + (1-\lambda)y) \leq \lambda f(x) + (1-\lambda) f(y)$$

```
      f(x)
        â†‘
        â”‚    Funkcja wypukÅ‚a
        â”‚         /\
        â”‚        /  \
        â”‚       /    \      CiÄ™ciwa zawsze
        â”‚      /â”€â”€â”€â”€â”€â”€\     powyÅ¼ej wykresu
        â”‚     /        \
        â”‚    /          \
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ x

      f(x)
        â†‘    Funkcja wklÄ™sÅ‚a (concave)
        â”‚    ________
        â”‚   /        \
        â”‚  /          \    CiÄ™ciwa zawsze
        â”‚ /â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\   poniÅ¼ej wykresu
        â”‚/              \
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ x
```

---

### 3. Znaczenie wypukÅ‚oÅ›ci

#### WÅ‚asnoÅ›ci problemÃ³w wypukÅ‚ych

| WÅ‚asnoÅ›Ä‡ | Opis |
|----------|------|
| **Global = Local** | KaÅ¼de minimum lokalne jest globalne |
| **JednoznacznoÅ›Ä‡** | ZbiÃ³r optymalnych jest wypukÅ‚y |
| **EfektywnoÅ›Ä‡** | Algorytmy wielomianowe (interior point) |
| **DualnoÅ›Ä‡** | Silna dualnoÅ›Ä‡ (zero duality gap) |
| **Warunki KKT** | WystarczajÄ…ce dla optimum |

#### PorÃ³wnanie zÅ‚oÅ¼onoÅ›ci

```
Problem          â”‚ ZÅ‚oÅ¼onoÅ›Ä‡      â”‚ Gwarancja
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LP               â”‚ Wielomianowa   â”‚ Globalne opt.
Convex QP        â”‚ Wielomianowa   â”‚ Globalne opt.
Convex NLP       â”‚ Wielomianowa   â”‚ Globalne opt.
Non-convex NLP   â”‚ NP-trudna      â”‚ Lokalne opt.
MINLP            â”‚ NP-trudna      â”‚ (zaleÅ¼y)
```

---

### 4. LiniowoÅ›Ä‡ vs nieliniowoÅ›Ä‡

#### Programowanie liniowe (LP)

$$\min c^T x \quad \text{s.t.} \quad Ax \leq b, \quad x \geq 0$$

```
Cechy LP:
âœ“ Optimum w wierzchoÅ‚ku (jeÅ›li istnieje)
âœ“ Simplex: pivotuje miÄ™dzy wierzchoÅ‚kami
âœ“ Interior Point: przez wnÄ™trze
âœ“ Zawsze wypukÅ‚e
âœ“ Silna dualnoÅ›Ä‡
```

#### Programowanie nieliniowe (NLP)

$$\min f(x) \quad \text{s.t.} \quad g_i(x) \leq 0, \quad h_j(x) = 0$$

```
Typy nieliniowoÅ›ci:

1. Kwadratowa (QP):
   min x'Qx + c'x  s.t. Ax â‰¤ b
   
   Q â‰» 0 (dodatnio okreÅ›lona) â†’ wypukÅ‚e
   Q ma ujemne eigenvalues â†’ niewypukÅ‚e

2. OgÃ³lna nieliniowa:
   min sin(x) + xÂ²Â·y
   s.t. xÂ² + yÂ² â‰¤ 1
   
   MoÅ¼e byÄ‡ wypukÅ‚a lub nie
```

---

### 5. Testowanie wypukÅ‚oÅ›ci

#### Dla funkcji

```
f(x) jest wypukÅ‚a jeÅ›li:

1. HESJAN: H = âˆ‡Â²f(x) â‰½ 0 (dodatnio pÃ³Å‚okreÅ›lony) dla wszystkich x

2. Kompozycja:
   - Suma wypukÅ‚ych â†’ wypukÅ‚a
   - max(f, g) gdzie f, g wypukÅ‚e â†’ wypukÅ‚a
   - f(Ax+b) gdzie f wypukÅ‚a â†’ wypukÅ‚a

3. Znane funkcje wypukÅ‚e:
   - xÂ², eË£, -log(x), |x|, max(x,0)
   - Normy: ||x||â‚, ||x||â‚‚
```

#### Dla zbiorÃ³w

```
ZbiÃ³r S jest wypukÅ‚y jeÅ›li:

1. PrzekrÃ³j wypukÅ‚ych â†’ wypukÅ‚y
2. {x: Ax â‰¤ b} â†’ wieloÅ›cian (wypukÅ‚y)
3. {x: ||x||â‚‚ â‰¤ r} â†’ kula (wypukÅ‚a)
4. {x: f(x) â‰¤ Î±} gdzie f wypukÅ‚a â†’ sublevel set (wypukÅ‚y)
```

---

### 6. Problemy niewypukÅ‚e

#### Konsekwencje

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PROBLEM NIEWYPUKÅY:                                             â”‚
â”‚                                                                 â”‚
â”‚ f(x)                                                            â”‚
â”‚   â†‘        â—                                                    â”‚
â”‚   â”‚       / \      â—  â† lokalne minimum                        â”‚
â”‚   â”‚      /   \    /â”‚\                                           â”‚
â”‚   â”‚     /     \  / â”‚ \                                          â”‚
â”‚   â”‚    /       \/  â”‚  \                                         â”‚
â”‚   â”‚   /    â—      â”‚   \    â— â† globalne minimum                â”‚
â”‚   â”‚  /   local    â”‚    \  /                                     â”‚
â”‚   â”‚ /     min     â”‚     \/                                      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ x                                  â”‚
â”‚                                                                 â”‚
â”‚ Algorytmy gradientowe znajdÄ… LOKALNE minimum!                   â”‚
â”‚ Nie ma gwarancji znalezienia globalnego.                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Strategie dla niewypukÅ‚ych

| Strategia | Opis |
|-----------|------|
| **Multi-start** | Wiele punktÃ³w startowych |
| **Global solvers** | BARON, Couenne, SCIP |
| **Relaxation** | Convex relaxation + B&B |
| **Metaheurystyki** | GA, SA, PSO |
| **Reformulation** | PrzeformuÅ‚uj na wypukÅ‚y |

---

### 7. PrzykÅ‚ady praktyczne

#### WypukÅ‚y - Portfolio optimization

```
Markowitz:
min  x'Î£x          (wariancja, Q = Î£ â‰» 0 â†’ wypukÅ‚e!)
s.t. Î¼'x â‰¥ r       (minimalny zwrot)
     Î£x_i = 1      (peÅ‚na inwestycja)
     x â‰¥ 0         (brak short selling)

Jest WYPUKÅY â†’ globalne optimum gwarantowane
```

#### NiewypukÅ‚y - Pooling problem

```
Mieszanie strumieni o rÃ³Å¼nych jakoÅ›ciach:

q_out = Î£(q_i Â· flow_i) / Î£ flow_i

Zawiera ILOCZYN zmiennych (bilinear) â†’ NIEWYPUKÅY
Tylko lokalne optimum gwarantowane (chyba Å¼e global solver)
```

#### Granica - SVM

```
Hard margin SVM (separowalne dane):
min  ||w||Â²
s.t. y_i(wÂ·x_i + b) â‰¥ 1

Jest WYPUKÅY (QP z liniowymi ograniczeniami)

Kernel SVM - nadal wypukÅ‚y w przestrzeni dualnej!
```

---

### 8. DualnoÅ›Ä‡

```
Primal (P):               Dual (D):
min f(x)                  max L(Î», Î¼)
s.t. g(x) â‰¤ 0             s.t. Î» â‰¥ 0
     h(x) = 0

Lagrangian: L(x,Î»,Î¼) = f(x) + Î»áµ€g(x) + Î¼áµ€h(x)

SÅABA DUALNOÅšÄ† (zawsze):
  d* â‰¤ p*  (dual â‰¤ primal)

SILNA DUALNOÅšÄ† (dla wypukÅ‚ych + constraint qualification):
  d* = p*  (zero duality gap)

Duality gap dla niewypukÅ‚ych moÅ¼e byÄ‡ > 0!
```

---

## ğŸ§  Mnemoniki

### "Convex = Global Local":
Dla wypukÅ‚ych: kaÅ¼de lokalne = globalne

### "Hesjan â‰» 0 = wypukÅ‚e":
Dodatnio okreÅ›lona macierz drugich pochodnych

### "LP âŠ‚ QP âŠ‚ Convex NLP":
KaÅ¼dy LP jest QP, kaÅ¼dy QP (z Qâ‰¥0) jest Convex NLP

---

## â“ Pytania dodatkowe

### Q1: "Jak rozpoznaÄ‡ czy problem jest wypukÅ‚y?"
**OdpowiedÅº:** SprawdÅº: (1) czy f celu ma Hesjan â‰¥ 0, (2) czy ograniczenia nierÃ³wnoÅ›ciowe g_i sÄ… wypukÅ‚e, (3) czy ograniczenia rÃ³wnoÅ›ciowe h_j sÄ… liniowe. JeÅ›li wszystkie TAK â†’ wypukÅ‚y.

### Q2: "Co zrobiÄ‡ gdy problem jest niewypukÅ‚y?"
**OdpowiedÅº:** Multi-start, global solvers (BARON), convex relaxation, reformulation (np. SDP relaxation dla QCQP), metaheurystyki, decomposition methods.

### Q3: "Czy MILP jest wypukÅ‚y?"
**OdpowiedÅº:** Nie w klasycznym sensie (zmienne dyskretne). Ale LP relaxation jest wypukÅ‚a. Branch & Bound wykorzystuje wypukÅ‚oÅ›Ä‡ relaksacji do pruning.

---

## ğŸ¯ Kluczowe punkty

1. **WypukÅ‚oÅ›Ä‡:** Global = Local, efektywne algorytmy
2. **NiewypukÅ‚oÅ›Ä‡:** Wiele minimÃ³w lokalnych, NP-trudne
3. **Hesjan:** âˆ‡Â²f â‰¥ 0 â†’ funkcja wypukÅ‚a
4. **LP zawsze wypukÅ‚y**, QP zaleÅ¼y od Q
5. **Silna dualnoÅ›Ä‡** dla wypukÅ‚ych

---

## ğŸ“– Å¹rÃ³dÅ‚a

1. Boyd, Vandenberghe - "Convex Optimization"
2. Nocedal, Wright - "Numerical Optimization"
3. Bazaraa et al. - "Nonlinear Programming"
