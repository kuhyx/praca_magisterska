# Pytanie 34: Analityka danych strumieniowych

## Pytanie
**"ScharakteryzowaÄ‡ rozwiÄ…zania analityczne dziaÅ‚ajÄ…ce na danych o charakterze strumieniowym."**

Przedmiot: PSD (Przetwarzanie Strumieniowe Danych)

---

## ğŸ“š OdpowiedÅº gÅ‚Ã³wna

### 1. Charakterystyka danych strumieniowych

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DANE STRUMIENIOWE vs BATCH                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ BATCH:                                                          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚ â”‚  Dane statyczne         â”‚ â†’ Przetwarzanie â†’ Wynik            â”‚
â”‚ â”‚  (caÅ‚y zbiÃ³r)           â”‚    (jednorazowe)                   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                                 â”‚
â”‚ STREAMING:                                                      â”‚
â”‚ â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â—â”€â”€â”€â”€â”€â—â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â†’ (nieskoÅ„czony strumieÅ„)   â”‚
â”‚      â”‚    â”‚  â”‚     â”‚  â”‚    â”‚                                    â”‚
â”‚      â†“    â†“  â†“     â†“  â†“    â†“                                    â”‚
â”‚   [Przetwarzanie ciÄ…gÅ‚e] â†’ Wyniki w czasie rzeczywistym        â”‚
â”‚                                                                 â”‚
â”‚ Cechy strumieni:                                                â”‚
â”‚ â€¢ Nieograniczone (unbounded)                                   â”‚
â”‚ â€¢ CiÄ…gÅ‚e napÅ‚ywanie                                            â”‚
â”‚ â€¢ Brak moÅ¼liwoÅ›ci przechowania wszystkiego                     â”‚
â”‚ â€¢ Wymagana niska latencja                                      â”‚
â”‚ â€¢ Dane mogÄ… byÄ‡ nieuporzÄ…dkowane (out-of-order)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2. Modele przetwarzania

#### Event Time vs Processing Time

```
Event Time:     Kiedy zdarzenie faktycznie nastÄ…piÅ‚o
Processing Time: Kiedy zdarzenie dotarÅ‚o do systemu

Timeline:
Event time:     â”€â—â”€â”€â”€â”€â”€â—â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â†’
                 E1    E2  E3        E4

Processing:     â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â†’
                   E1      E3 E2 E4 (rÃ³Å¼na kolejnoÅ›Ä‡!)

Watermark: znacznik postÄ™pu event time
  "Wszystkie zdarzenia do czasu T juÅ¼ dotarÅ‚y"
```

#### Windowing (okna czasowe)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TUMBLING WINDOW (rozÅ‚Ä…czne):                                    â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
â”‚ â”‚ Window1â”‚â”‚ Window2â”‚â”‚ Window3â”‚â”‚ Window4â”‚                       â”‚
â”‚                                                                 â”‚
â”‚ SLIDING WINDOW (nakÅ‚adajÄ…ce siÄ™):                              â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                                  â”‚
â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                              â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                          â”‚
â”‚             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                                      â”‚
â”‚                                                                 â”‚
â”‚ SESSION WINDOW (oparte na aktywnoÅ›ci):                         â”‚
â”‚ â”œâ”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”¤                      â”‚
â”‚ session1    session2    s3       session4                      â”‚
â”‚        gap         gap      gap                                 â”‚
â”‚                                                                 â”‚
â”‚ GLOBAL WINDOW:                                                  â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’        â”‚
â”‚ (jedno okno, trigger decyduje kiedy emitowaÄ‡)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 3. Platformy Stream Processing

#### Apache Kafka Streams

```java
StreamsBuilder builder = new StreamsBuilder();

KStream<String, String> source = builder.stream("input-topic");

KTable<Windowed<String>, Long> counts = source
    .groupByKey()
    .windowedBy(TimeWindows.of(Duration.ofMinutes(5)))
    .count();

counts.toStream().to("output-topic");

// Cechy:
// â€¢ Library (nie cluster)
// â€¢ Exactly-once semantics
// â€¢ Stateful processing z RocksDB
// â€¢ Integracja z Kafka ecosystem
```

#### Apache Flink

```java
DataStream<Event> stream = env.addSource(new FlinkKafkaConsumer<>(...));

DataStream<Result> result = stream
    .keyBy(event -> event.getKey())
    .window(TumblingEventTimeWindows.of(Time.minutes(5)))
    .aggregate(new MyAggregateFunction())
    .process(new MyProcessFunction());

// Cechy:
// â€¢ True streaming (nie micro-batch)
// â€¢ Event time processing
// â€¢ Exactly-once state
// â€¢ Savepoints & checkpoints
// â€¢ Complex Event Processing (CEP)
```

#### Apache Spark Structured Streaming

```python
df = spark.readStream \
    .format("kafka") \
    .option("subscribe", "events") \
    .load()

result = df \
    .withWatermark("timestamp", "10 minutes") \
    .groupBy(
        window("timestamp", "5 minutes"),
        "userId"
    ) \
    .count()

query = result.writeStream \
    .outputMode("append") \
    .format("console") \
    .start()

# Cechy:
# â€¢ Micro-batch (domyÅ›lnie) lub Continuous
# â€¢ Unified batch + streaming API
# â€¢ Catalyst optimizer
# â€¢ Integracja z Spark ecosystem
```

---

### 4. PorÃ³wnanie platform

| Cecha | Kafka Streams | Flink | Spark Streaming |
|-------|---------------|-------|-----------------|
| **Model** | True streaming | True streaming | Micro-batch |
| **Deployment** | Library | Cluster | Cluster |
| **Latency** | Niska | Bardzo niska | Åšrednia (~100ms) |
| **State** | RocksDB | RocksDB/heap | In-memory/external |
| **Exactly-once** | Tak | Tak | Tak |
| **SQL** | KSQL | Flink SQL | Spark SQL |
| **CEP** | Ograniczone | Tak (FlinkCEP) | Nie natywnie |

---

### 5. Algorytmy strumieniowe

#### Approximate counting - HyperLogLog

```
Problem: Zlicz unikalne elementy w strumieniu
         (bez przechowywania wszystkich)

HyperLogLog:
â€¢ O(1) space (kilka KB)
â€¢ ~2% error dla 12-bit registers
â€¢ UÅ¼ywa hash â†’ trailing zeros

PrzykÅ‚ad: Redis PFADD, PFCOUNT
```

#### Frequency estimation - Count-Min Sketch

```
Problem: Estymuj czÄ™stoÅ›Ä‡ elementÃ³w

Count-Min Sketch:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ h1: [3][0][2][5][1][0][4][2]   â”‚
â”‚ h2: [1][2][0][3][4][1][0][2]   â”‚
â”‚ h3: [2][1][3][0][2][1][3][0]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Query(x): min(h1[hash1(x)], h2[hash2(x)], h3[hash3(x)])

â€¢ Overestimates (never underestimates)
â€¢ Tunable accuracy vs space
```

#### Sampling - Reservoir Sampling

```
Problem: RÃ³wnomiernie prÃ³bkuj k elementÃ³w
         ze strumienia o nieznanej dÅ‚ugoÅ›ci

Algorithm:
1. Zachowaj pierwsze k elementÃ³w
2. Dla i-tego elementu (i > k):
   - Z prawdopodobieÅ„stwem k/i zamieÅ„
     losowy element w reservoir

Gwarancja: KaÅ¼dy element ma szansÄ™ k/n
```

---

### 6. ObsÅ‚uga opÃ³ÅºnieÅ„ i Out-of-Order

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WATERMARKS + LATE DATA                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Stream:    â”€â—(t=1)â”€â”€â—(t=5)â”€â”€â—(t=3)â”€â”€â—(t=8)â”€â”€â—(t=2)â”€â”€â”€â†’         â”‚
â”‚                       â†‘                       â†‘                 â”‚
â”‚                    out-of-order           late data            â”‚
â”‚                                                                 â”‚
â”‚ Watermark: "Prawdopodobnie wszystkie events do t=X dotarÅ‚y"    â”‚
â”‚                                                                 â”‚
â”‚ Strategie dla late data:                                        â”‚
â”‚ 1. DROP: Ignoruj spÃ³Åºnione (najprostsze)                       â”‚
â”‚ 2. RECOMPUTE: Przelicz okno (kosztowne)                        â”‚
â”‚ 3. SIDE OUTPUT: Zapisz do osobnego strumienia                  â”‚
â”‚ 4. ALLOWED LATENESS: Czekaj dodatkowo N czasu                  â”‚
â”‚                                                                 â”‚
â”‚ Flink:                                                          â”‚
â”‚   .allowedLateness(Time.minutes(5))                            â”‚
â”‚   .sideOutputLateData(lateOutputTag)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 7. Exactly-Once Semantics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GWARANCJE PRZETWARZANIA:                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ AT-MOST-ONCE:                                                   â”‚
â”‚   Fire-and-forget, moÅ¼liwa utrata danych                       â”‚
â”‚                                                                 â”‚
â”‚ AT-LEAST-ONCE:                                                  â”‚
â”‚   Retry przy failure, moÅ¼liwe duplikaty                        â”‚
â”‚                                                                 â”‚
â”‚ EXACTLY-ONCE:                                                   â”‚
â”‚   KaÅ¼de zdarzenie przetworzone dokÅ‚adnie raz                   â”‚
â”‚                                                                 â”‚
â”‚ Implementacja (Flink/Kafka):                                    â”‚
â”‚ â€¢ Checkpointing (periodic snapshots)                           â”‚
â”‚ â€¢ Transactional sinks (Kafka transactions)                     â”‚
â”‚ â€¢ Barrier alignment                                             â”‚
â”‚ â€¢ Idempotent operations                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 8. Use Cases

| Use Case | Technologia | Opis |
|----------|-------------|------|
| **Fraud detection** | Flink CEP | Pattern matching w czasie rzeczywistym |
| **IoT analytics** | Kafka Streams | Agregacja danych z sensorÃ³w |
| **Real-time dashboards** | Spark + Druid | Metryki biznesowe |
| **Log analysis** | ELK + Kafka | Centralizacja logÃ³w |
| **Recommendations** | Flink | Real-time personalizacja |

---

## ğŸ§  Mnemoniki

### "TWSS = Tumbling, Window, Sliding, Session":
Cztery typy okien czasowych

### "Flink = Fast, Spark = Safe":
Flink najszybszy (true streaming), Spark bezpieczny (micro-batch)

### "HLL = Hash, Leading zeros, Log":
HyperLogLog do zliczania unikalnych

---

## â“ Pytania dodatkowe

### Q1: "Kiedy micro-batch a kiedy true streaming?"
**OdpowiedÅº:** True streaming (Flink): ultra-low latency, CEP, event-time critical. Micro-batch (Spark): wyÅ¼sza przepustowoÅ›Ä‡, Å‚atwiejsza integracja z batch, mniej wraÅ¼liwe na anomalie.

### Q2: "Jak obsÅ‚uÅ¼yÄ‡ skoki danych (spikes)?"
**OdpowiedÅº:** Backpressure (Flink automatycznie), buffering, auto-scaling (Kubernetes), rate limiting na ÅºrÃ³dle, spillage to disk.

### Q3: "Co to jest checkpointing?"
**OdpowiedÅº:** Periodic snapshots stanu (Flink). Przy failure - restart od ostatniego checkpoointu. Barrier synchronizuje snapshot miÄ™dzy operatorami. Incremental checkpoints dla duÅ¼ych stanÃ³w.

---

## ğŸ¯ Kluczowe punkty

1. **Streaming:** Unbounded, continuous, low latency
2. **Windowing:** Tumbling, Sliding, Session, Global
3. **Event time vs Processing time:** Watermarks
4. **Platforms:** Flink (true), Spark (micro-batch), Kafka Streams (library)
5. **Exactly-once:** Checkpointing + transactions

---

## ğŸ“– Å¹rÃ³dÅ‚a

1. Kleppmann - "Designing Data-Intensive Applications"
2. Apache Flink Documentation
3. Spark Structured Streaming Guide
4. Kafka Streams Documentation
