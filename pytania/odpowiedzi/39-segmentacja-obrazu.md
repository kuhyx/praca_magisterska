# Pytanie 39: Segmentacja obrazu

## Pytanie
**"ScharakteryzowaÄ‡ problem segmentacji obrazu. PrzedstawiÄ‡ podstawowe strategie i algorytmy segmentacji przy uÅ¼yciu metod klasycznych oraz sieci neuronowych."**

Przedmiot: TWM (Techniki Wizji Maszynowej)

---

## ğŸ“š OdpowiedÅº gÅ‚Ã³wna

### 1. Definicja problemu segmentacji

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                SEGMENTACJA OBRAZU                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Obraz wejÅ›ciowy:              Maska segmentacji:              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  â”‚            â”‚  â–‘â–‘1111â–‘â–‘â–‘â–‘â–‘â–‘  â”‚              â”‚
â”‚  â”‚  â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘  â”‚     â†’      â”‚  â–‘11111111â–‘â–‘â–‘  â”‚              â”‚
â”‚  â”‚  â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  â”‚            â”‚  â–‘â–‘11111111â–‘â–‘  â”‚              â”‚
â”‚  â”‚  â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  â”‚            â”‚  â–‘â–‘â–‘â–‘1111â–‘â–‘â–‘â–‘  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                 â”‚
â”‚  Cel: PrzypisaÄ‡ kaÅ¼demu pikselowi etykietÄ™ klasy/regionu       â”‚
â”‚                                                                 â”‚
â”‚  Typy segmentacji:                                              â”‚
â”‚  â€¢ Semantic: klasa dla kaÅ¼dego piksela (person, car, sky)      â”‚
â”‚  â€¢ Instance: rozrÃ³Å¼nia instancje tej samej klasy               â”‚
â”‚  â€¢ Panoptic: semantic + instance (unified)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2. Metody klasyczne

#### 2.1 Thresholding (progowanie)

```
Globalne:
  pixel_out = 255 if pixel_in > T else 0

Otsu (automatyczny prÃ³g):
  - Maksymalizuje wariancjÄ™ miÄ™dzy klasami
  - ÏƒÂ²_between = wâ‚€wâ‚(Î¼â‚€ - Î¼â‚)Â²

Adaptacyjne:
  - Lokalny prÃ³g dla kaÅ¼dego regionu
  - T(x,y) = mean(neighborhood) - C

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Threshold    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚â–‘â–’â–“â–ˆâ–‘â–’â–“â–ˆâ–‘â–’â–“â–ˆâ–‘â–’â–“â–ˆ  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  â”‚â–‘â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆ  â”‚
â”‚â–’â–“â–ˆâ–‘â–’â–“â–ˆâ–‘â–’â–“â–ˆâ–‘â–’â–“â–ˆâ–‘  â”‚       T        â”‚â–‘â–ˆâ–ˆâ–ˆâ–‘â–ˆâ–ˆâ–ˆâ–‘â–ˆâ–ˆâ–ˆâ–‘â–ˆâ–ˆâ–ˆâ–‘  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2.2 Region Growing

```
Algorytm:
1. Wybierz punkt startowy (seed)
2. Badaj sÄ…siadÃ³w
3. JeÅ›li podobny (|I(neighbor) - I(region)| < threshold)
   â†’ dodaj do regionu
4. Powtarzaj aÅ¼ brak nowych pikseli

  Seed    Krok 1    Krok 2    Wynik
   â—        â—â—       â—â—â—      â—â—â—â—
            â—        â—â—â—      â—â—â—â—
                     â—â—       â—â—â—â—
```

#### 2.3 Watershed

```
Obraz jako topografia:
- IntensywnoÅ›Ä‡ = wysokoÅ›Ä‡
- "Zalewanie" od minimÃ³w lokalnych
- Granice gdzie woda z rÃ³Å¼nych ÅºrÃ³deÅ‚ siÄ™ spotyka

      â•±â•²      â•±â•²
     â•±  â•²    â•±  â•²
    â•±    â•²__â•±    â•²
   â•±      â†‘       â•²
  â†‘    granica     â†‘
 min1  (watershed) min2
```

#### 2.4 Mean Shift

```
Iteracyjne przesuwanie okna do maksimum gÄ™stoÅ›ci:

1. Dla kaÅ¼dego piksela:
   m(x) = Î£ K(x - xáµ¢) Ã— xáµ¢ / Î£ K(x - xáµ¢)
   
2. x â† m(x) (shift)
3. Powtarzaj do zbieÅ¼noÅ›ci
4. Piksele zbiegajÄ…ce do tego samego punktu â†’ jeden segment
```

#### 2.5 Graph-based (Normalized Cuts)

```
Obraz jako graf:
- WierzchoÅ‚ki = piksele
- KrawÄ™dzie = podobieÅ„stwo miÄ™dzy pikselami
- w(i,j) = exp(-||I(i) - I(j)||Â² / ÏƒÂ²)

Normalized Cut:
  Ncut(A,B) = cut(A,B)/assoc(A,V) + cut(A,B)/assoc(B,V)

Minimalizacja Ncut â†’ eigendecomposition Laplacianu
```

---

### 3. PorÃ³wnanie metod klasycznych

| Metoda | Zalety | Wady |
|--------|--------|------|
| **Thresholding** | Szybki, prosty | Tylko 2 klasy, wraÅ¼liwy na oÅ›wietlenie |
| **Region Growing** | Intuicyjny | Wymaga seedÃ³w, over-segmentation |
| **Watershed** | Dobre krawÄ™dzie | Over-segmentation |
| **Mean Shift** | Brak k | Wolny, parametr bandwidth |
| **Graph Cut** | Globalnie optymalne | O(nÂ³), wymaga unary terms |

---

### 4. Metody deep learning

#### 4.1 FCN (Fully Convolutional Network)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FCN - pierwsza architektura deep dla segmentacji (2015)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Input     Encoder (VGG)      Decoder                   Output  â”‚
â”‚ HÃ—WÃ—3  â†’  Conv+PoolÃ—5  â†’  Upsampling (deconv)  â†’  HÃ—WÃ—C       â”‚
â”‚                                                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”   â”Œâ”€â”€â”   â”Œâ”€â”€â”                    â”Œâ”€â”€â”€â”€â”                 â”‚
â”‚ â”‚    â”‚ â†’ â”‚  â”‚ â†’ â”‚  â”‚ â†’ Â·Â·Â· â†’ upsample â†’ â”‚    â”‚                 â”‚
â”‚ â”‚    â”‚   â”‚  â”‚   â”‚  â”‚          Ã—32       â”‚    â”‚                 â”‚
â”‚ â””â”€â”€â”€â”€â”˜   â””â”€â”€â”˜   â””â”€â”€â”˜                    â””â”€â”€â”€â”€â”˜                 â”‚
â”‚  input   conv   conv                    output                 â”‚
â”‚                                                                 â”‚
â”‚ Skip connections: FCN-32s, FCN-16s, FCN-8s                     â”‚
â”‚ Coarser + finer features â†’ sharper boundaries                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 4.2 U-Net

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ U-NET - encoder-decoder ze skip connections (2015)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚     Encoder              Decoder                               â”‚
â”‚       â”‚                    â†‘                                    â”‚
â”‚    â”Œâ”€â”€â”´â”€â”€â”  â”€ copy â”€â†’  â”Œâ”€â”€â”´â”€â”€â”                                â”‚
â”‚    â”‚64Ã—64â”‚              â”‚64Ã—64â”‚                                â”‚
â”‚    â””â”€â”€â”¬â”€â”€â”˜              â””â”€â”€â”¬â”€â”€â”˜                                â”‚
â”‚       â†“                    â†‘                                    â”‚
â”‚    â”Œâ”€â”€â”´â”€â”€â”  â”€ copy â”€â†’  â”Œâ”€â”€â”´â”€â”€â”                                â”‚
â”‚    â”‚32Ã—32â”‚              â”‚32Ã—32â”‚                                â”‚
â”‚    â””â”€â”€â”¬â”€â”€â”˜              â””â”€â”€â”¬â”€â”€â”˜                                â”‚
â”‚       â†“                    â†‘                                    â”‚
â”‚    â”Œâ”€â”€â”´â”€â”€â”  â”€ copy â”€â†’  â”Œâ”€â”€â”´â”€â”€â”                                â”‚
â”‚    â”‚16Ã—16â”‚              â”‚16Ã—16â”‚                                â”‚
â”‚    â””â”€â”€â”¬â”€â”€â”˜              â””â”€â”€â”¬â”€â”€â”˜                                â”‚
â”‚       â†“                    â†‘                                    â”‚
â”‚       â””â”€â”€â”€â”€â”€ bottleneck â”€â”€â”€â”˜                                   â”‚
â”‚                                                                 â”‚
â”‚ Concat skip connections (nie add jak w ResNet)                 â”‚
â”‚ Popularne w medycynie (maÅ‚e datasety)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 4.3 DeepLab (v1-v3+)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DEEPLAB - Atrous/Dilated Convolutions + CRF                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Atrous Convolution (dilated):                                   â”‚
â”‚                                                                 â”‚
â”‚ Standard 3Ã—3:        Atrous 3Ã—3, rate=2:                       â”‚
â”‚ â— â— â—                â—   â—   â—                                 â”‚
â”‚ â— â— â—                              (wiÄ™ksze receptive field    â”‚
â”‚ â— â— â—                â—   â—   â—      bez wiÄ™cej parametrÃ³w)     â”‚
â”‚                                                                 â”‚
â”‚                      â—   â—   â—                                 â”‚
â”‚                                                                 â”‚
â”‚ ASPP (Atrous Spatial Pyramid Pooling):                         â”‚
â”‚ Parallel atrous conv z rÃ³Å¼nymi rates (6, 12, 18)              â”‚
â”‚ â†’ multi-scale context                                          â”‚
â”‚                                                                 â”‚
â”‚ DeepLabv3+:                                                     â”‚
â”‚ Encoder-decoder + ASPP + depthwise separable conv              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 4.4 Transformer-based (SegFormer, Mask2Former)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SEGFORMER (2021)                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚ Mix-Transformer encoder:                                       â”‚
â”‚ â€¢ Hierarchical features (1/4, 1/8, 1/16, 1/32)               â”‚
â”‚ â€¢ Efficient self-attention                                     â”‚
â”‚ â€¢ No positional encoding                                       â”‚
â”‚                                                                 â”‚
â”‚ MLP decoder:                                                    â”‚
â”‚ â€¢ Simple MLP combines multi-scale features                     â”‚
â”‚ â€¢ Lightweight                                                   â”‚
â”‚                                                                 â”‚
â”‚ MASK2FORMER (2022):                                            â”‚
â”‚ â€¢ Universal: semantic, instance, panoptic                      â”‚
â”‚ â€¢ Masked attention (per-segment)                               â”‚
â”‚ â€¢ Deformable attention                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 5. PorÃ³wnanie architektur DL

| Architektura | mIoU (ADE20K) | Parametry | Cechy |
|--------------|---------------|-----------|-------|
| **FCN** | ~30% | ~135M | Pierwsze DL dla segmentacji |
| **U-Net** | - | ~31M | Medical, skip connections |
| **DeepLabv3+** | ~45% | ~60M | ASPP, dilated conv |
| **SegFormer-B5** | ~51% | ~85M | Transformer, efficient |
| **Mask2Former** | ~57% | ~200M | Universal, SOTA |

---

### 6. Loss functions

```
Cross-Entropy Loss:
  L = -Î£áµ¢ Î£c yáµ¢c log(páµ¢c)
  
  Problem: class imbalance (duÅ¼o tÅ‚a, maÅ‚o obiektÃ³w)

Dice Loss:
  L = 1 - 2|X âˆ© Y| / (|X| + |Y|)
  
  BezpoÅ›rednio optymalizuje IoU-like metric

Focal Loss:
  L = -Î±â‚œ(1 - pâ‚œ)^Î³ log(pâ‚œ)
  
  Î³ > 0 â†’ hard examples waÅ¼niejsze

Combined:
  L = Î»â‚ Â· CE + Î»â‚‚ Â· Dice
```

---

### 7. Metryki

| Metryka | FormuÅ‚a | Opis |
|---------|---------|------|
| **Pixel Accuracy** | TP / (TP+FP+FN+TN) | % poprawnych pikseli |
| **IoU (Jaccard)** | TP / (TP+FP+FN) | Intersection over Union |
| **mIoU** | mean IoU per class | Standard dla segmentacji |
| **Dice** | 2TP / (2TP+FP+FN) | F1 dla segmentacji |

---

## ğŸ§  Mnemoniki

### "U-Net = U-shaped skip":
KsztaÅ‚t U z skip connections

### "ASPP = Atrous at Multiple Scales":
DeepLab's Atrous Spatial Pyramid Pooling

### "IoU = Intersection / Union":
Podstawowa metryka segmentacji

---

## â“ Pytania dodatkowe

### Q1: "Jak radziÄ‡ sobie z class imbalance?"
**OdpowiedÅº:** Weighted cross-entropy, Focal Loss, oversampling maÅ‚ych klas, Dice Loss (ignoruje dominacjÄ™ duÅ¼ych klas), OHEM (Online Hard Example Mining).

### Q2: "U-Net vs DeepLab?"
**OdpowiedÅº:** U-Net: encoder-decoder z concat skip, dobre dla maÅ‚ych datasetÃ³w (medical). DeepLab: dilated conv zachowuje resolution, ASPP dla multi-scale, lepsze dla duÅ¼ych datasetÃ³w.

### Q3: "Co to jest panoptic segmentation?"
**OdpowiedÅº:** Unified semantic + instance. Dzieli na "stuff" (nieczÄ™Å›ciowe: sky, road) i "things" (policzalne: person, car). KaÅ¼dy piksel ma class ID + instance ID.

---

## ğŸ¯ Kluczowe punkty

1. **Klasyczne:** Thresholding, Region Growing, Watershed, Graph Cut
2. **FCN:** Pierwszy fully convolutional dla segmentacji
3. **U-Net:** Encoder-decoder + skip connections
4. **DeepLab:** Dilated/Atrous conv, ASPP
5. **Metryka:** mIoU (mean Intersection over Union)

---

## ğŸ“– Å¹rÃ³dÅ‚a

1. Long et al. - "Fully Convolutional Networks" (2015)
2. Ronneberger et al. - "U-Net" (2015)
3. Chen et al. - "DeepLab" series (2014-2018)
4. Xie et al. - "SegFormer" (2021)
